# pages/2_ë§¤ì¶œ_ë¶„ì„.py (ê²€ìƒ‰ ì‹œ regex=False ì¶”ê°€ ë° Cloudìš© ìˆ˜ì •)

import streamlit as st
import pandas as pd
import datetime
# import os # os.path.existsëŠ” ë” ì´ìƒ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
import traceback
# import numpy as np # í˜„ì¬ ì½”ë“œì—ì„œ ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ

# common_utils.py ì—ì„œ ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
from common_utils import download_excel_from_drive_as_bytes

# --- Google Drive íŒŒì¼ ID ì •ì˜ ---
# ì‚¬ìš©ìë‹˜ì´ ì œê³µí•´ì£¼ì‹  ì‹¤ì œ íŒŒì¼ IDë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
SALES_FILE_ID = "1h-V7kIoInXgGLll7YBW5V_uZdF3Q1PdY" # ë§¤ì¶œë‚´ì—­ íŒŒì¼ ID
# --- íŒŒì¼ ID ì •ì˜ ë ---

# --- ì´ í˜ì´ì§€ ê³ ìœ ì˜ ì„¤ì • ---
SALES_SHEET_NAME = 's-list' # ë§¤ì¶œë‚´ì—­ íŒŒì¼ì˜ ì‹œíŠ¸ ì´ë¦„

# ì»¬ëŸ¼ëª… ìƒìˆ˜ (ì œê³µëœ ì½”ë“œ ê¸°ì¤€)
DATE_COL = 'ë§¤ì¶œì¼ì'
AMOUNT_COL = 'ë§¤ì¶œê¸ˆì•¡'
WEIGHT_COL = 'ìˆ˜ëŸ‰(Kg)'
CUSTOMER_COL = 'ê±°ë˜ì²˜ëª…'
PRODUCT_COL = 'ìƒ  í’ˆ  ëª…' # ì›ë³¸ íŒŒì¼ì˜ ìƒí’ˆëª… ì»¬ëŸ¼ (ê³µë°± 2ì¹¸ í¬í•¨ ê°€ëŠ¥ì„± ìˆìŒ)
PRICE_COL = 'ë§¤ì¶œë‹¨ê°€'


# --- Google Drive ì„œë¹„ìŠ¤ ê°ì²´ ê°€ì ¸ì˜¤ê¸° ---
retrieved_drive_service = st.session_state.get('drive_service')
page_title_for_debug = "ë§¤ì¶œ ë¶„ì„ í˜ì´ì§€" 

if retrieved_drive_service:
    st.sidebar.info(f"'{page_title_for_debug}'ì—ì„œ Drive Service ë¡œë“œ ì„±ê³µ!")
else:
    st.sidebar.error(f"'{page_title_for_debug}'ì—ì„œ Drive Service ë¡œë“œ ì‹¤íŒ¨! (None). ë©”ì¸ í˜ì´ì§€ë¥¼ ë¨¼ì € ë°©ë¬¸í•˜ì—¬ ì¸ì¦ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")

drive_service = retrieved_drive_service


@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None}) # drive_service í•´ì‹œ ë°©ì§€
def load_sales_data(_drive_service, file_id_sales, sheet_name):
    """ë§¤ì¶œ ë¡œê·¸ ë°ì´í„°ë¥¼ Google Driveì—ì„œ ë¡œë“œí•˜ê³  ê¸°ë³¸ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    if _drive_service is None:
        st.error("ì˜¤ë¥˜: Google Drive ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ë§¤ì¶œ ë°ì´í„° ë¡œë”©)")
        return None

    file_bytes_sales = download_excel_from_drive_as_bytes(_drive_service, file_id_sales, f"ë§¤ì¶œë‚´ì—­ ({sheet_name})")
    if file_bytes_sales is None:
        # download_excel_from_drive_as_bytes í•¨ìˆ˜ ë‚´ì—ì„œ ì´ë¯¸ st.errorë¥¼ í˜¸ì¶œí•¨
        return None
        
    try:
        required_cols = [DATE_COL, AMOUNT_COL, WEIGHT_COL, CUSTOMER_COL, PRODUCT_COL, PRICE_COL]
        df = pd.read_excel(file_bytes_sales, sheet_name=sheet_name)
        
        if not all(col in df.columns for col in required_cols):
            missing_cols = [col for col in required_cols if col not in df.columns]
            st.error(f"ì˜¤ë¥˜: ë§¤ì¶œ ë‚´ì—­ ì‹œíŠ¸ '{sheet_name}'ì— í•„ìš”í•œ ì»¬ëŸ¼({missing_cols}) ì—†ìŒ")
            st.write(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {df.columns.tolist()}")
            return None
            
        df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors='coerce')
        df[AMOUNT_COL] = pd.to_numeric(df[AMOUNT_COL], errors='coerce').fillna(0)
        df[WEIGHT_COL] = pd.to_numeric(df[WEIGHT_COL], errors='coerce').fillna(0)
        df[PRICE_COL] = pd.to_numeric(df[PRICE_COL], errors='coerce').fillna(0)
        df[CUSTOMER_COL] = df[CUSTOMER_COL].astype(str).str.strip()
        df[PRODUCT_COL] = df[PRODUCT_COL].astype(str).str.strip() # ìƒí’ˆëª… ì»¬ëŸ¼ ê³µë°± ì œê±°
            
        original_rows = len(df)
        df.dropna(subset=[DATE_COL], inplace=True) # ë‚ ì§œ ëˆ„ë½ í–‰ ì œê±°
        if len(df) < original_rows: 
            st.warning(f"'{DATE_COL}' í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆê±°ë‚˜ ë¹„ì–´ìˆëŠ” {original_rows - len(df)}ê°œ í–‰ì´ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        if df.empty:
            st.warning("ì „ì²˜ë¦¬ í›„ ë‚¨ì€ ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame() # ë¹ˆ DataFrame ë°˜í™˜
        return df
    except ValueError as ve:
        if sheet_name and f"Worksheet named '{sheet_name}' not found" in str(ve): 
            st.error(f"ì˜¤ë¥˜: ë§¤ì¶œ ë‚´ì—­ íŒŒì¼ (ID: {file_id_sales})ì— '{sheet_name}' ì‹œíŠ¸ ì—†ìŒ")
        else: 
            st.error(f"ë§¤ì¶œ ë°ì´í„° (ID: {file_id_sales}, ì‹œíŠ¸: {sheet_name}) ë¡œë“œ ì¤‘ ê°’ ì˜¤ë¥˜: {ve}")
        return None
    except Exception as e: 
        st.error(f"ë§¤ì¶œ ë°ì´í„° (ID: {file_id_sales}, ì‹œíŠ¸: {sheet_name}) ë¡œë“œ ì¤‘ ì˜ˆìƒ ëª»í•œ ì˜¤ë¥˜: {e}")
        # traceback.print_exc() # ë””ë²„ê¹… ì‹œ í•„ìš”í•˜ë©´ ì£¼ì„ í•´ì œ
        return None

# --- Streamlit í˜ì´ì§€ êµ¬ì„± ---
st.title("ğŸ“ˆ ë§¤ì¶œ ë¶„ì„")
st.markdown("---")

if drive_service is None: 
    st.error("Google Drive ì„œë¹„ìŠ¤ì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•±ì˜ ë©”ì¸ í˜ì´ì§€ë¥¼ ë°©ë¬¸í•˜ì—¬ ì¸ì¦ì„ ì™„ë£Œí•˜ê±°ë‚˜, ì•± ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

df_sales_loaded = load_sales_data(drive_service, SALES_FILE_ID, SALES_SHEET_NAME)

if df_sales_loaded is None:
    st.error("ë§¤ì¶œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. Google Drive íŒŒì¼ ID, ì‹œíŠ¸ ì´ë¦„, íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
elif df_sales_loaded.empty:
    st.warning("ì²˜ë¦¬í•  ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (íŒŒì¼ì€ ì½ì—ˆìœ¼ë‚˜ ë‚´ìš©ì´ ë¹„ì–´ìˆê±°ë‚˜ ëª¨ë‘ í•„í„°ë§ë¨).")
else:
    st.success(f"ë§¤ì¶œ ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df_sales_loaded)} í–‰")
    today = pd.Timestamp.today().normalize()
    # ê¸°ë³¸ ë¶„ì„ ê¸°ê°„ì„ ë¡œë“œëœ ë°ì´í„°ì˜ ìµœê·¼ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •í•˜ë„ë¡ ë³€ê²½ ê³ ë ¤ ê°€ëŠ¥
    # ì—¬ê¸°ì„œëŠ” ê¸°ì¡´ ë¡œì§(ì˜¤ëŠ˜ ê¸°ì¤€ ìµœê·¼ 90ì¼)ì„ ìœ ì§€í•˜ë˜, ë°ì´í„°ê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„
    
    min_data_date = df_sales_loaded[DATE_COL].min()
    max_data_date = df_sales_loaded[DATE_COL].max()

    # ë‚ ì§œ ì„ íƒ UI ê°œì„ : ë°ì´í„°ê°€ ìˆëŠ” ë²”ìœ„ ë‚´ì—ì„œ ì„ íƒí•˜ë„ë¡ ìœ ë„
    date_range_col1, date_range_col2 = st.columns(2)
    with date_range_col1:
        start_date_input = st.date_input(
            "ë¶„ì„ ì‹œì‘ì¼", 
            value=max_data_date - pd.Timedelta(days=89) if not pd.isna(max_data_date) else today - pd.Timedelta(days=89),
            min_value=min_data_date if not pd.isna(min_data_date) else None,
            max_value=max_data_date if not pd.isna(max_data_date) else today,
            key="sales_start_date"
        )
    with date_range_col2:
        end_date_input = st.date_input(
            "ë¶„ì„ ì¢…ë£Œì¼", 
            value=max_data_date if not pd.isna(max_data_date) else today,
            min_value=start_date_input if start_date_input else (min_data_date if not pd.isna(min_data_date) else None),
            max_value=max_data_date if not pd.isna(max_data_date) else today,
            key="sales_end_date"
        )
    
    start_date = pd.Timestamp(start_date_input)
    end_date = pd.Timestamp(end_date_input)

    st.info(f"ì„ íƒëœ ë¶„ì„ ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
    
    df_filtered_global = df_sales_loaded[
        (df_sales_loaded[DATE_COL] >= start_date) & 
        (df_sales_loaded[DATE_COL] <= end_date)
    ].copy()

    if df_filtered_global.empty:
        st.warning("ì„ íƒëœ ê¸°ê°„ ë‚´ì— í•´ë‹¹í•˜ëŠ” ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        col1, col2 = st.columns([2, 3]) # ë ˆì´ì•„ì›ƒ ë¹„ìœ¨ ì¡°ì •

        with col2: # ê²€ìƒ‰ ì¡°ê±´ ë° ìƒì„¸ ë‚´ì—­
            st.header("ğŸ” ì¡°ê±´ë³„ ë§¤ì¶œ ìƒì„¸ ì¡°íšŒ")
            st.markdown("ê±°ë˜ì²˜ëª… ë˜ëŠ” í’ˆëª©ëª…(ì¼ë¶€ ë˜ëŠ” ì „ì²´)ì„ ì…ë ¥í•˜ì—¬ ì„ íƒëœ ê¸°ê°„ì˜ ìƒì„¸ ë§¤ì¶œ ë‚´ì—­ ë° ê´€ë ¨ ê·¸ë˜í”„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
            customer_input_raw = st.text_input("ê±°ë˜ì²˜ëª… ê²€ìƒ‰:", key="sales_customer_input")
            product_input_raw = st.text_input("í’ˆëª©ëª… ê²€ìƒ‰:", key="sales_product_input")

            customer_input = customer_input_raw.strip()
            product_input = product_input_raw.strip()

            df_for_display = df_filtered_global.copy() # ê²€ìƒ‰ì„ ìœ„í•´ ì›ë³¸ í•„í„°ëœ ë°ì´í„° ë³µì‚¬
            filter_active = False
            active_filters = []

            if customer_input:
                df_for_display = df_for_display[df_for_display[CUSTOMER_COL].str.contains(customer_input, case=False, na=False, regex=False)]
                filter_active = True
                active_filters.append(f"ê±°ë˜ì²˜: '{customer_input}'")
            if product_input:
                df_for_display = df_for_display[df_for_display[PRODUCT_COL].str.contains(product_input, case=False, na=False, regex=False)]
                filter_active = True
                active_filters.append(f"í’ˆëª©: '{product_input}'")
            
            if filter_active:
                st.markdown("---")
                st.subheader(f"'{' / '.join(active_filters) if active_filters else 'ì „ì²´'}' ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼")
                st.write(f"ì´ {len(df_for_display)} ê±´ì˜ ë§¤ì¶œ ë‚´ì—­ì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
                if not df_for_display.empty:
                    display_cols_detail = [DATE_COL, CUSTOMER_COL, PRODUCT_COL, WEIGHT_COL, PRICE_COL, AMOUNT_COL]
                    valid_display_cols_detail = [col for col in display_cols_detail if col in df_for_display.columns]
                    df_display_detail = df_for_display[valid_display_cols_detail].copy()
                    
                    df_display_detail[DATE_COL] = df_display_detail[DATE_COL].dt.strftime('%Y-%m-%d')
                    df_display_detail.sort_values(by=DATE_COL, ascending=False, inplace=True)
                    st.dataframe(df_display_detail, hide_index=True, use_container_width=True, height=300) # ë†’ì´ ì§€ì •
                else:
                    st.info("í•´ë‹¹ ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ìƒì„¸ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
            elif not customer_input_raw and not product_input_raw:
                st.info("ê±°ë˜ì²˜ëª… ë˜ëŠ” í’ˆëª©ëª…ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ë©´ í•´ë‹¹ ì¡°ê±´ì˜ ìƒì„¸ ë‚´ì—­ ë° ê·¸ë˜í”„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
        
        with col1: # ê·¸ë˜í”„ í‘œì‹œ
            graph_title_suffix = ""
            if filter_active:
                graph_title_suffix = f" ({', '.join(active_filters)})"
            
            st.header(f"ğŸ“Š ì¼ë³„ ë§¤ì¶œ ì¶”ì´{graph_title_suffix}")
            if not filter_active :
                st.markdown(f"ì„ íƒëœ ê¸°ê°„({start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')})ì˜ ì „ì²´ ì¼ë³„ ë§¤ì¶œ ê¸ˆì•¡ê³¼ íŒë§¤ ì¤‘ëŸ‰(Kg) ì¶”ì„¸ì…ë‹ˆë‹¤.")
            else:
                st.markdown(f"ê²€ìƒ‰ ì¡°ê±´ì— ë”°ë¥¸ ì„ íƒëœ ê¸°ê°„ì˜ ì¼ë³„ ë§¤ì¶œ ê¸ˆì•¡ê³¼ íŒë§¤ ì¤‘ëŸ‰(Kg) ì¶”ì„¸ì…ë‹ˆë‹¤.")

            if df_for_display.empty:
                st.warning("ì„ íƒëœ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                daily_summary = df_for_display.groupby(pd.Grouper(key=DATE_COL, freq='D'))[[AMOUNT_COL, WEIGHT_COL]].sum()
                # ê·¸ë˜í”„ í‘œì‹œ ì „, í•©ê³„ê°€ 0ì¸ ë‚ ì§œëŠ” ì œì™¸ (ì„ íƒ ì‚¬í•­)
                daily_summary_for_chart = daily_summary[~((daily_summary[AMOUNT_COL] == 0) & (daily_summary[WEIGHT_COL] == 0))]
                
                if daily_summary_for_chart.empty:
                    st.write("ê·¸ë˜í”„ì— í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë“  ë‚ ì§œì˜ í•©ê³„ê°€ 0ì´ê±°ë‚˜ ë°ì´í„° ì—†ìŒ).")
                else:
                    daily_summary_for_chart = daily_summary_for_chart.copy() # SettingWithCopyWarning ë°©ì§€
                    # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½ ì‹œ, ì›ë³¸ WEIGHT_COL ìƒìˆ˜ ê°’ì„ í¬í•¨í•˜ì—¬ ëª…í™•íˆ í•¨
                    daily_summary_for_chart.rename(columns={AMOUNT_COL: 'ë§¤ì¶œ ê¸ˆì•¡(ì›)', WEIGHT_COL: f'íŒë§¤ ì¤‘ëŸ‰({WEIGHT_COL})'}, inplace=True)

                    st.subheader("ê¸ˆì•¡ (ì›)")
                    st.line_chart(daily_summary_for_chart[['ë§¤ì¶œ ê¸ˆì•¡(ì›)']], use_container_width=True)

                    st.subheader(f"ì¤‘ëŸ‰ ({WEIGHT_COL})") # WEIGHT_COL ìƒìˆ˜ ì‚¬ìš©
                    st.line_chart(daily_summary_for_chart[[f'íŒë§¤ ì¤‘ëŸ‰({WEIGHT_COL})']], use_container_width=True)

                with st.expander("ì„ íƒ ì¡°ê±´ ì¼ë³„ ìš”ì•½ ë°ì´í„° ë³´ê¸°"):
                    # ê²€ìƒ‰ ì¡°ê±´ì´ ì ìš©ëœ df_for_displayë¥¼ ì‚¬ìš©
                    daily_summary_table_data = df_for_display.groupby(pd.Grouper(key=DATE_COL, freq='D'))[[AMOUNT_COL, WEIGHT_COL]].sum().reset_index()
                    if daily_summary_table_data.empty:
                        st.write("ìš”ì•½í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        weekday_map = {0: 'ì›”', 1: 'í™”', 2: 'ìˆ˜', 3: 'ëª©', 4: 'ê¸ˆ', 5: 'í† ', 6: 'ì¼'}
                        daily_summary_table_data['ìš”ì¼'] = daily_summary_table_data[DATE_COL].dt.dayofweek.map(weekday_map)
                        daily_summary_table_data[DATE_COL] = daily_summary_table_data[DATE_COL].dt.strftime('%Y-%m-%d')
                        daily_summary_table_data.rename(columns={AMOUNT_COL: 'ë§¤ì¶œ ê¸ˆì•¡(ì›)', WEIGHT_COL: f'íŒë§¤ ì¤‘ëŸ‰({WEIGHT_COL})'}, inplace=True)
                        
                        display_columns = [DATE_COL, 'ìš”ì¼', 'ë§¤ì¶œ ê¸ˆì•¡(ì›)', f'íŒë§¤ ì¤‘ëŸ‰({WEIGHT_COL})']
                        st.dataframe(daily_summary_table_data[display_columns], use_container_width=True, hide_index=True)
