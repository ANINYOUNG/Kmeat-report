# pages/4_ì¬ê³ _ë³´ì¶©_ì œì•ˆ.py (ImportError ë° Cloudìš© ìˆ˜ì •, ì¶œê³ ë¹ˆë„ í•„í„° ì¶”ê°€)

import streamlit as st
import pandas as pd
import datetime
from dateutil.relativedelta import relativedelta
import io # BytesIO ì‚¬ìš©ì„ ìœ„í•´ í•„ìš”
import traceback # ì˜ˆì™¸ ì²˜ë¦¬ìš©

# common_utils.py ì—ì„œ ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
# DATA_FOLDER, SM_FILEì€ ë¡œì»¬ ê²½ë¡œì´ë¯€ë¡œ common_utilsì—ì„œ ê°€ì ¸ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤.
# get_all_available_sheet_dates ëŒ€ì‹  get_all_available_sheet_dates_from_bytesë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
from common_utils import download_excel_from_drive_as_bytes, get_all_available_sheet_dates_from_bytes

# --- Google Drive íŒŒì¼ ID ì •ì˜ ---
SALES_FILE_ID = "1h-V7kIoInXgGLll7YBW5V_uZdF3Q1PdY"  # ë§¤ì¶œë‚´ì—­ íŒŒì¼ ID
SM_FILE_ID = "1tRljdvOpp4fITaVEXvoL9mNveNg2qt4p"    # SMì¬ê³ í˜„í™© íŒŒì¼ ID
# --- íŒŒì¼ ID ì •ì˜ ë ---

# --- ì´ í˜ì´ì§€ ê³ ìœ ì˜ ì„¤ì • ---
SALES_DATA_SHEET_NAME = 's-list' # ë§¤ì¶œë‚´ì—­ íŒŒì¼ì˜ ì‹œíŠ¸ ì´ë¦„

# ì»¬ëŸ¼ëª… ìƒìˆ˜
SALES_DATE_COL = 'ë§¤ì¶œì¼ì'
SALES_PROD_CODE_COL = 'ìƒí’ˆì½”ë“œ'
SALES_PROD_NAME_COL = 'ìƒ  í’ˆ  ëª…' 
SALES_QTY_BOX_COL = 'ìˆ˜ëŸ‰(Box)'
SALES_QTY_KG_COL = 'ìˆ˜ëŸ‰(Kg)'
SALES_LOCATION_COL = 'ì§€ì ëª…'

CURRENT_STOCK_PROD_CODE_COL = 'ìƒí’ˆì½”ë“œ'
CURRENT_STOCK_PROD_NAME_COL = 'ìƒí’ˆëª…'
CURRENT_STOCK_QTY_COL = 'ì”ëŸ‰(ë°•ìŠ¤)'
CURRENT_STOCK_WGT_COL = 'ì”ëŸ‰(Kg)'
CURRENT_STOCK_LOCATION_COL = 'ì§€ì ëª…'

# --- Google Drive ì„œë¹„ìŠ¤ ê°ì²´ ê°€ì ¸ì˜¤ê¸° ---
retrieved_drive_service = st.session_state.get('drive_service')
page_title_for_debug = "ì¬ê³  ë³´ì¶© ì œì•ˆ í˜ì´ì§€" 

if retrieved_drive_service:
    st.sidebar.info(f"'{page_title_for_debug}'ì—ì„œ Drive Service ë¡œë“œ ì„±ê³µ!")
else:
    st.sidebar.error(f"'{page_title_for_debug}'ì—ì„œ Drive Service ë¡œë“œ ì‹¤íŒ¨! (None). ë©”ì¸ í˜ì´ì§€ë¥¼ ë¨¼ì € ë°©ë¬¸í•˜ì—¬ ì¸ì¦ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")

drive_service = retrieved_drive_service

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def load_sales_history_and_filter_3m(_drive_service, file_id_sales, sheet_name, num_months=3):
    """
    ì§€ì •ëœ Google Drive íŒŒì¼/ì‹œíŠ¸ì—ì„œ ì „ì²´ ë§¤ì¶œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ ,
    ì§€ë‚œ Nê°œì˜ ì™„ì „í•œ ë‹¬ë ¥ ì›” ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ì—¬ 
    [ìƒí’ˆì½”ë“œ, ìƒí’ˆëª…, ì§€ì ëª…]ë³„ ì´ ì¶œê³ ëŸ‰ ë° ë§¤ì¶œ ë°œìƒì¼ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if _drive_service is None:
        st.error("ì˜¤ë¥˜: Google Drive ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ë§¤ì¶œ ë°ì´í„° ë¡œë”©)")
        return pd.DataFrame()

    file_bytes_sales = download_excel_from_drive_as_bytes(_drive_service, file_id_sales, f"ë§¤ì¶œë‚´ì—­ ({sheet_name})")
    if file_bytes_sales is None:
        return pd.DataFrame()
        
    try:
        required_cols = [SALES_DATE_COL, SALES_PROD_CODE_COL, SALES_PROD_NAME_COL, 
                         SALES_QTY_BOX_COL, SALES_QTY_KG_COL, SALES_LOCATION_COL]
        
        df = pd.read_excel(file_bytes_sales, sheet_name=sheet_name)
        
        if not all(col in df.columns for col in required_cols):
            missing_cols = [col for col in required_cols if col not in df.columns]
            st.error(f"ì˜¤ë¥˜: ë§¤ì¶œ ë‚´ì—­ ì‹œíŠ¸ '{sheet_name}' (ID: {file_id_sales})ì— í•„ìš”í•œ ì»¬ëŸ¼({missing_cols}) ì—†ìŒ")
            st.write(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {df.columns.tolist()}")
            return pd.DataFrame()
        
        df[SALES_DATE_COL] = pd.to_datetime(df[SALES_DATE_COL], errors='coerce')
        df.dropna(subset=[SALES_DATE_COL], inplace=True)
        
        df[SALES_PROD_CODE_COL] = df[SALES_PROD_CODE_COL].astype(str).str.strip()
        df[SALES_PROD_NAME_COL] = df[SALES_PROD_NAME_COL].astype(str).str.strip()
        df[SALES_LOCATION_COL] = df[SALES_LOCATION_COL].astype(str).str.strip()
        df[SALES_QTY_BOX_COL] = pd.to_numeric(df[SALES_QTY_BOX_COL], errors='coerce').fillna(0)
        df[SALES_QTY_KG_COL] = pd.to_numeric(df[SALES_QTY_KG_COL], errors='coerce').fillna(0)

        if df.empty:
            st.warning(f"ë§¤ì¶œë‚´ì—­ íŒŒì¼ (ID: {file_id_sales}, ì‹œíŠ¸: {sheet_name})ì— ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        today = pd.Timestamp.today().normalize()
        first_day_of_current_month = today.replace(day=1)
        end_date_of_last_full_month = first_day_of_current_month - pd.Timedelta(days=1) 
        start_date_of_analysis_period = (end_date_of_last_full_month + pd.Timedelta(days=1) - pd.DateOffset(months=num_months)).replace(day=1)
        
        st.info(f"ë§¤ì¶œ ë¶„ì„ ê¸°ê°„ (ì§€ë‚œ {num_months}ê°œì›”): {start_date_of_analysis_period.strftime('%Y-%m-%d')} ~ {end_date_of_last_full_month.strftime('%Y-%m-%d')}")

        df_filtered = df[
            (df[SALES_DATE_COL] >= start_date_of_analysis_period) &
            (df[SALES_DATE_COL] <= end_date_of_last_full_month)
        ].copy()

        if df_filtered.empty:
            st.warning(f"ì„ íƒëœ ê¸°ê°„ì˜ ë§¤ì¶œ ë°ì´í„°ê°€ '{sheet_name}' ì‹œíŠ¸ì— ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        # [ìƒí’ˆì½”ë“œ, ìƒí’ˆëª…, ì§€ì ëª…]ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì´ ì¶œê³ ëŸ‰ê³¼ *ë§¤ì¶œ ë°œìƒì¼ ìˆ˜* ì§‘ê³„
        total_sales_by_item_loc = df_filtered.groupby(
            [SALES_PROD_CODE_COL, SALES_PROD_NAME_COL, SALES_LOCATION_COL], 
            as_index=False
        ).agg(
            TotalQtyBox=(SALES_QTY_BOX_COL, 'sum'),
            TotalQtyKg=(SALES_QTY_KG_COL, 'sum'),
            SalesDays=(SALES_DATE_COL, 'nunique') # <<< ë³€ê²½ì : ë§¤ì¶œ ë°œìƒ ê³ ìœ  ì¼ì ìˆ˜ ì¶”ê°€
        )
        return total_sales_by_item_loc
    except ValueError as ve:
        if sheet_name and f"Worksheet named '{sheet_name}' not found" in str(ve):
            st.error(f"ì˜¤ë¥˜: ë§¤ì¶œ íŒŒì¼ (ID: {file_id_sales})ì— '{sheet_name}' ì‹œíŠ¸ ì—†ìŒ")
        else:
            st.error(f"ë§¤ì¶œ ë°ì´í„° (ID: {file_id_sales}) ë¡œë“œ ì¤‘ ê°’ ì˜¤ë¥˜: {ve}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"ë§¤ì¶œ ë°ì´í„° (ID: {file_id_sales}) ë¡œë“œ/ì²˜ë¦¬ ì¤‘ ì˜ˆìƒ ëª»í•œ ì˜¤ë¥˜: {e}")
        st.error(traceback.format_exc()) # ìƒì„¸ ì˜¤ë¥˜ ë¡œê·¸ ì¶”ê°€
        return pd.DataFrame()

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def load_current_stock_data(_drive_service, file_id_sm):
    """SMì¬ê³ í˜„í™© íŒŒì¼ì˜ ìµœì‹  ë‚ ì§œ ì‹œíŠ¸ì—ì„œ í˜„ì¬ê³  ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if _drive_service is None:
        st.error("ì˜¤ë¥˜: Google Drive ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (í˜„ì¬ê³  ë°ì´í„° ë¡œë”©)")
        return pd.DataFrame()

    sm_file_bytes = download_excel_from_drive_as_bytes(_drive_service, file_id_sm, "SMì¬ê³ í˜„í™© (í˜„ì¬ê³  ì¡°íšŒìš©)")
    if not sm_file_bytes:
        return pd.DataFrame() 

    available_sm_dates = get_all_available_sheet_dates_from_bytes(sm_file_bytes, "SMì¬ê³ í˜„í™© (í˜„ì¬ê³  ì¡°íšŒìš©)")
    if not available_sm_dates:
        st.warning(f"SMì¬ê³ í˜„í™© íŒŒì¼ (ID: {file_id_sm})ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì¬ê³  ë°ì´í„° ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    latest_date_obj = available_sm_dates[0] 
    latest_date_str = latest_date_obj.strftime("%Y%m%d")
    st.info(f"í˜„ì¬ê³  ê¸°ì¤€ì¼: {latest_date_obj.strftime('%Y-%m-%d')} (ì‹œíŠ¸: {latest_date_str})")

    try:
        sm_file_bytes.seek(0) 
        df_stock_raw = pd.read_excel(sm_file_bytes, sheet_name=latest_date_str)
        
        required_stock_cols = [CURRENT_STOCK_PROD_CODE_COL, CURRENT_STOCK_PROD_NAME_COL, 
                               CURRENT_STOCK_QTY_COL, CURRENT_STOCK_WGT_COL, CURRENT_STOCK_LOCATION_COL]
        
        if not all(col in df_stock_raw.columns for col in required_stock_cols):
            missing = [col for col in required_stock_cols if col not in df_stock_raw.columns]
            st.error(f"í˜„ì¬ê³  ë°ì´í„° ì‹œíŠ¸({latest_date_str}, ID: {file_id_sm})ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}.")
            st.error("ì½”ë“œ ìƒë‹¨ì˜ í˜„ì¬ê³  ê´€ë ¨ ìƒìˆ˜(CURRENT_STOCK_..._COL)ì™€ ì‹¤ì œ ì—‘ì…€ íŒŒì¼ì˜ ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        df_stock_raw[CURRENT_STOCK_PROD_CODE_COL] = df_stock_raw[CURRENT_STOCK_PROD_CODE_COL].astype(str).str.strip()
        df_stock_raw[CURRENT_STOCK_PROD_NAME_COL] = df_stock_raw[CURRENT_STOCK_PROD_NAME_COL].astype(str).str.strip()
        df_stock_raw[CURRENT_STOCK_LOCATION_COL] = df_stock_raw[CURRENT_STOCK_LOCATION_COL].astype(str).str.strip()
        df_stock_raw[CURRENT_STOCK_QTY_COL] = pd.to_numeric(df_stock_raw[CURRENT_STOCK_QTY_COL], errors='coerce').fillna(0)
        df_stock_raw[CURRENT_STOCK_WGT_COL] = pd.to_numeric(df_stock_raw[CURRENT_STOCK_WGT_COL], errors='coerce').fillna(0)

        current_stock_by_item_loc = df_stock_raw.groupby(
            [CURRENT_STOCK_PROD_CODE_COL, CURRENT_STOCK_PROD_NAME_COL, CURRENT_STOCK_LOCATION_COL], 
            as_index=False
        ).agg(
            CurrentQty=(CURRENT_STOCK_QTY_COL, 'sum'),
            CurrentWgt=(CURRENT_STOCK_WGT_COL, 'sum')
        )
        
        if current_stock_by_item_loc.empty and not df_stock_raw.empty:
            st.warning(f"í˜„ì¬ê³  ë°ì´í„° ê·¸ë£¹í•‘ í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ ({latest_date_str}, ID: {file_id_sm}).")
            return pd.DataFrame()
        return current_stock_by_item_loc
    except ValueError as ve:
        if latest_date_str and f"Worksheet named '{latest_date_str}' not found" in str(ve):
            st.error(f"ì˜¤ë¥˜: í˜„ì¬ê³  íŒŒì¼ (ID: {file_id_sm})ì— '{latest_date_str}' ì‹œíŠ¸ ì—†ìŒ")
        else:
            st.error(f"í˜„ì¬ê³  ë°ì´í„° (ID: {file_id_sm}) ë¡œë“œ ì¤‘ ê°’ ì˜¤ë¥˜: {ve}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"í˜„ì¬ê³  ë°ì´í„° (ID: {file_id_sm}, ì‹œíŠ¸: {latest_date_str}) ë¡œë“œ/ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        st.error(traceback.format_exc()) # ìƒì„¸ ì˜¤ë¥˜ ë¡œê·¸ ì¶”ê°€
        return pd.DataFrame()

# --- Streamlit í˜ì´ì§€ UI ë° ë¡œì§ ---
st.title("ğŸ“¦ ì¬ê³  ë³´ì¶© ì œì•ˆ ë³´ê³ ì„œ (ì§€ì ë³„)")

if drive_service is None: 
    st.error("Google Drive ì„œë¹„ìŠ¤ì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•±ì˜ ë©”ì¸ í˜ì´ì§€ë¥¼ ë°©ë¬¸í•˜ì—¬ ì¸ì¦ì„ ì™„ë£Œí•˜ê±°ë‚˜, ì•± ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# <<< ë³€ê²½ì : í•„í„°ë§ ì¡°ê±´ ì„¤ëª… ì¶”ê°€ ---
MIN_SALES_DAYS_PER_MONTH = 5 
st.markdown(f"""
ìµœê·¼ 3ê°œì›”ê°„ì˜ ì›”í‰ê·  ì¶œê³ ëŸ‰ê³¼ í˜„ì¬ê³ ë¥¼ **ì§€ì ë³„ë¡œ** ë¹„êµí•˜ì—¬ ë³´ì¶© í•„ìš” ìˆ˜ëŸ‰ì„ ì œì•ˆí•©ë‹ˆë‹¤.
**ë‹¨, ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜ê°€ {MIN_SALES_DAYS_PER_MONTH}ì¼ ì´ìƒì¸ í’ˆëª©ë§Œ ëŒ€ìƒ**ìœ¼ë¡œ í•©ë‹ˆë‹¤.
""")
# --- ë³€ê²½ì  ë ---

st.markdown(f"ë§¤ì¶œ ë°ì´í„° ì›ë³¸: Google Drive íŒŒì¼ (ID: `{SALES_FILE_ID}`)ì˜ '{SALES_DATA_SHEET_NAME}' ì‹œíŠ¸")
st.markdown(f"í˜„ì¬ê³  ë°ì´í„° ì›ë³¸: Google Drive íŒŒì¼ (ID: `{SM_FILE_ID}`)ì˜ ìµœì‹  ë‚ ì§œ ì‹œíŠ¸")
st.markdown("---")

num_months_to_analyze = 3
df_total_sales_3m = load_sales_history_and_filter_3m(drive_service, SALES_FILE_ID, SALES_DATA_SHEET_NAME, num_months=num_months_to_analyze)
df_current_stock = load_current_stock_data(drive_service, SM_FILE_ID)

if df_total_sales_3m.empty or df_current_stock.empty:
    st.warning("ë§¤ì¶œ ë°ì´í„° ë˜ëŠ” í˜„ì¬ê³  ë°ì´í„°ê°€ ì—†ì–´ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ ë¡œê·¸ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    df_avg_monthly_sales = df_total_sales_3m.copy()
    
    # <<< ë³€ê²½ì : ì›”í‰ê·  ì¶œê³ ëŸ‰ ë° ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜ ê³„ì‚° ---
    df_avg_monthly_sales['ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)'] = (df_avg_monthly_sales['TotalQtyBox'] / num_months_to_analyze).round(2)
    df_avg_monthly_sales['ì›”í‰ê·  ì¶œê³ ëŸ‰(Kg)'] = (df_avg_monthly_sales['TotalQtyKg'] / num_months_to_analyze).round(2)
    # 'SalesDays'ëŠ” num_months_to_analyze ê¸°ê°„ ë™ì•ˆì˜ ì´ ì¶œê³ ì¼ìˆ˜ì´ë¯€ë¡œ, ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜ë¡œ ë³€í™˜
    df_avg_monthly_sales['ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜'] = (df_avg_monthly_sales['SalesDays'] / num_months_to_analyze).round(2)
    # --- ë³€ê²½ì  ë ---

    # <<< ë³€ê²½ì : ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§ ---
    df_avg_monthly_sales_filtered = df_avg_monthly_sales[df_avg_monthly_sales['ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜'] >= MIN_SALES_DAYS_PER_MONTH].copy()
    
    if df_avg_monthly_sales_filtered.empty:
        st.warning(f"ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜ê°€ {MIN_SALES_DAYS_PER_MONTH}ì¼ ì´ìƒì¸ í’ˆëª©ì´ ì—†ìŠµë‹ˆë‹¤. ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop() # í•„í„°ë§ í›„ ë°ì´í„° ì—†ìœ¼ë©´ ì¤‘ë‹¨
    else:
        st.success(f"ì´ {len(df_avg_monthly_sales)}ê°œ í’ˆëª©(ì§€ì ë³„) ì¤‘ ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜ {MIN_SALES_DAYS_PER_MONTH}ì¼ ì´ìƒì¸ {len(df_avg_monthly_sales_filtered)}ê°œ í’ˆëª©ì„ ëŒ€ìƒìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
    # --- ë³€ê²½ì  ë ---
    
    # í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ê³„ì† ì§„í–‰
    df_avg_monthly_sales_to_use = df_avg_monthly_sales_filtered.rename(columns={
        SALES_PROD_CODE_COL: 'ìƒí’ˆì½”ë“œ', 
        SALES_PROD_NAME_COL: 'ìƒí’ˆëª…',
        SALES_LOCATION_COL: 'ì§€ì ëª…'
    })
    df_avg_monthly_sales_to_use['ìƒí’ˆì½”ë“œ'] = df_avg_monthly_sales_to_use['ìƒí’ˆì½”ë“œ'].astype(str).str.strip().str.replace(r'\.0$', '', regex=True)
    df_avg_monthly_sales_to_use['ì§€ì ëª…'] = df_avg_monthly_sales_to_use['ì§€ì ëª…'].astype(str).str.strip()
    # 'ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜'ëŠ” í•„í„°ë§ ì¡°ê±´ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ê³  ìµœì¢… ë³´ê³ ì„œì—ì„œëŠ” ì œì™¸í•  ìˆ˜ ìˆìŒ (í•„ìš”ì‹œ í¬í•¨)
    df_avg_monthly_sales_to_use = df_avg_monthly_sales_to_use[['ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…', 'ì§€ì ëª…', 'ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)', 'ì›”í‰ê·  ì¶œê³ ëŸ‰(Kg)', 'ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜']]


    df_current_stock_report = df_current_stock.rename(columns={
        CURRENT_STOCK_PROD_CODE_COL: 'ìƒí’ˆì½”ë“œ',
        CURRENT_STOCK_PROD_NAME_COL: 'ìƒí’ˆëª…',
        CURRENT_STOCK_LOCATION_COL: 'ì§€ì ëª…',
        'CurrentQty': 'ì”ëŸ‰(ë°•ìŠ¤)',
        'CurrentWgt': 'ì”ëŸ‰(Kg)'
    })
    df_current_stock_report['ìƒí’ˆì½”ë“œ'] = df_current_stock_report['ìƒí’ˆì½”ë“œ'].astype(str).str.strip().str.replace(r'\.0$', '', regex=True)
    df_current_stock_report['ì§€ì ëª…'] = df_current_stock_report['ì§€ì ëª…'].astype(str).str.strip()
    df_current_stock_report = df_current_stock_report[['ìƒí’ˆì½”ë“œ', 'ì§€ì ëª…', 'ìƒí’ˆëª…', 'ì”ëŸ‰(ë°•ìŠ¤)', 'ì”ëŸ‰(Kg)']]

    df_report = pd.merge(
        df_avg_monthly_sales_to_use, 
        df_current_stock_report, 
        on=['ìƒí’ˆì½”ë“œ', 'ì§€ì ëª…'], 
        how='left', # ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜ ê¸°ì¤€ì„ í†µê³¼í•œ í’ˆëª© ê¸°ì¤€ìœ¼ë¡œ ì¬ê³ ë¥¼ ë¶™ì„
        suffixes=('_sales', '_stock') 
    )
        
    df_report['ìƒí’ˆëª…'] = df_report['ìƒí’ˆëª…_sales'].fillna(df_report['ìƒí’ˆëª…_stock'])
    df_report.drop(columns=['ìƒí’ˆëª…_sales', 'ìƒí’ˆëª…_stock'], inplace=True, errors='ignore')
    
    df_report['ì”ëŸ‰(ë°•ìŠ¤)'] = df_report['ì”ëŸ‰(ë°•ìŠ¤)'].fillna(0)
    df_report['ì”ëŸ‰(Kg)'] = df_report['ì”ëŸ‰(Kg)'].fillna(0)

    df_report['í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)'] = (df_report['ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)'] - df_report['ì”ëŸ‰(ë°•ìŠ¤)']).apply(lambda x: max(0, x)).round(2)
    df_report['í•„ìš”ìˆ˜ëŸ‰(Kg)'] = (df_report['ì›”í‰ê·  ì¶œê³ ëŸ‰(Kg)'] - df_report['ì”ëŸ‰(Kg)']).apply(lambda x: max(0, x)).round(2)
    
    final_report_columns = [
        'ì§€ì ëª…', 'ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…', 
        'ì”ëŸ‰(ë°•ìŠ¤)', 'ì”ëŸ‰(Kg)', 
        'ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)', 'ì›”í‰ê·  ì¶œê³ ëŸ‰(Kg)',
        'ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜', # <<< í•„ìš”ì‹œ ìµœì¢… ë³´ê³ ì„œì— í¬í•¨ (í™•ì¸ìš©)
        'í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)', 'í•„ìš”ìˆ˜ëŸ‰(Kg)'
    ]
    existing_final_cols = [col for col in final_report_columns if col in df_report.columns]
    df_report_final = df_report[existing_final_cols]

    df_report_final = df_report_final.sort_values(by=['ì§€ì ëª…', 'í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)'], ascending=[True, False])

    st.markdown("---")
    st.header("ğŸ“‹ ì¬ê³  ë³´ì¶© ì œì•ˆ ë¦¬ìŠ¤íŠ¸ (ì§€ì ë³„)")
    
    df_display = df_report_final.copy()

    if 'ìƒí’ˆì½”ë“œ' in df_display.columns:
        try:
            df_display['ìƒí’ˆì½”ë“œ'] = df_display['ìƒí’ˆì½”ë“œ'].astype(str).str.replace(r'\.0$', '', regex=True)
        except Exception as e:
            st.warning(f"ìƒí’ˆì½”ë“œ ë¬¸ìì—´ ë³€í™˜ ì¤‘ ê²½ë¯¸í•œ ì˜¤ë¥˜: {e}")
            df_display['ìƒí’ˆì½”ë“œ'] = df_display['ìƒí’ˆì½”ë“œ'].astype(str)

    cols_to_make_int_for_display = ['ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)', 'í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)', 'ì”ëŸ‰(ë°•ìŠ¤)']
    for col in cols_to_make_int_for_display:
        if col in df_display.columns:
            df_display[col] = pd.to_numeric(df_display[col], errors='coerce').fillna(0).round(0).astype('Int64')

    format_dict = {}
    for col in ['ì”ëŸ‰(ë°•ìŠ¤)', 'ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)', 'í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)']:
        if col in df_display.columns: 
            format_dict[col] = "{:,.0f}"
    
    for col in ['ì”ëŸ‰(Kg)', 'ì›”í‰ê·  ì¶œê³ ëŸ‰(Kg)', 'í•„ìš”ìˆ˜ëŸ‰(Kg)']:
        if col in df_display.columns: 
            format_dict[col] = "{:,.2f}"
    
    if 'ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜' in df_display.columns: # ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜ë„ ì†Œìˆ˜ì  2ìë¦¬ë¡œ í¬ë§·
        format_dict['ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜'] = "{:,.2f}"
        
    st.dataframe(df_display.style.format(format_dict, na_rep="-").set_properties(**{'text-align': 'right'}), use_container_width=True)

    @st.cache_data
    def convert_df_to_excel(df_to_convert):
        excel_stream = io.BytesIO()
        with pd.ExcelWriter(excel_stream, engine='xlsxwriter') as writer: 
            df_to_convert.to_excel(writer, index=False, sheet_name='ë³´ê³ ì„œ')
        excel_stream.seek(0)
        return excel_stream.getvalue()

    if not df_display.empty:
        excel_data = convert_df_to_excel(df_display)
        report_date_str = datetime.date.today().strftime("%Y%m%d")
        st.download_button(
            label="ğŸ“¥ ë³´ê³ ì„œ ì—‘ì…€ë¡œ ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f"ì¬ê³ ë³´ì¶©ì œì•ˆë³´ê³ ì„œ_ì§€ì ë³„_{report_date_str}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="download_replenishment_report_formatted_page_filtered" # í‚¤ ë³€ê²½
        )
