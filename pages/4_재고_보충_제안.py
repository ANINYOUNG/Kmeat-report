# pages/4_ì¬ê³ _ë³´ì¶©_ì œì•ˆ.py fix-20250613

import streamlit as st
import pandas as pd
import datetime
from dateutil.relativedelta import relativedelta
import io
import traceback
import plotly.express as px # ê·¸ë˜í”„ ìƒì„±ì„ ìœ„í•´ plotly ì¶”ê°€

# common_utils.py ì—ì„œ ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
from common_utils import download_excel_from_drive_as_bytes, get_all_available_sheet_dates_from_bytes

# --- Google Drive íŒŒì¼ ID ì •ì˜ ---
SALES_FILE_ID = "1h-V7kIoInXgGLll7YBW5V_uZdF3Q1PdY"  # ë§¤ì¶œë‚´ì—­ íŒŒì¼ ID
SM_FILE_ID = "1tRljdvOpp4fITaVEXvoL9mNveNg2qt4p"    # SMì¬ê³ í˜„í™© íŒŒì¼ ID
# --- íŒŒì¼ ID ì •ì˜ ë ---

# --- ì´ í˜ì´ì§€ ê³ ìœ ì˜ ì„¤ì • ---
SALES_DATA_SHEET_NAME = 's-list' # ë§¤ì¶œë‚´ì—­ íŒŒì¼ì˜ ì‹œíŠ¸ ì´ë¦„

# ì»¬ëŸ¼ëª… ìƒìˆ˜
SALES_DATE_COL = 'ë§¤ì¶œì¼ì'
SALES_PROD_CODE_COL = 'ìƒí’ˆì½”ë“œ'
SALES_PROD_NAME_COL = 'ìƒ  í’ˆ  ëª…' # ì›ë³¸ ì—‘ì…€ì˜ ì»¬ëŸ¼ëª…ì— ë§ì¶¤ (ê³µë°± ì£¼ì˜)
SALES_QTY_BOX_COL = 'ìˆ˜ëŸ‰(Box)'
SALES_QTY_KG_COL = 'ìˆ˜ëŸ‰(Kg)'
SALES_LOCATION_COL = 'ì§€ì ëª…'

CURRENT_STOCK_PROD_CODE_COL = 'ìƒí’ˆì½”ë“œ'
CURRENT_STOCK_PROD_NAME_COL = 'ìƒí’ˆëª…'
CURRENT_STOCK_QTY_COL = 'ì”ëŸ‰(ë°•ìŠ¤)'
CURRENT_STOCK_WGT_COL = 'ì”ëŸ‰(Kg)'
CURRENT_STOCK_LOCATION_COL = 'ì§€ì ëª…'

# --- Google Drive ì„œë¹„ìŠ¤ ê°ì²´ ê°€ì ¸ì˜¤ê¸° ---
retrieved_drive_service = st.session_state.get('drive_service')
page_title_for_debug = "ì¬ê³  ë³´ì¶© ì œì•ˆ í˜ì´ì§€"

if retrieved_drive_service:
    st.sidebar.info(f"'{page_title_for_debug}'ì—ì„œ Drive Service ë¡œë“œ ì„±ê³µ!")
else:
    st.sidebar.error(f"'{page_title_for_debug}'ì—ì„œ Drive Service ë¡œë“œ ì‹¤íŒ¨! (None). ë©”ì¸ í˜ì´ì§€ë¥¼ ë¨¼ì € ë°©ë¬¸í•˜ì—¬ ì¸ì¦ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")

drive_service = retrieved_drive_service

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def load_sales_history_and_filter_3m(_drive_service, file_id_sales, sheet_name, num_months=3):
    """
    ì§€ì •ëœ Google Drive íŒŒì¼/ì‹œíŠ¸ì—ì„œ ì „ì²´ ë§¤ì¶œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ ,
    ë§¤ì¶œ ë°ì´í„°ì˜ ê°€ì¥ ë§ˆì§€ë§‰ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì´ì „ 90ì¼ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ì—¬
    [ìƒí’ˆì½”ë“œ, ìƒí’ˆëª…, ì§€ì ëª…]ë³„ ì´ ì¶œê³ ëŸ‰ ë° ë§¤ì¶œ ë°œìƒì¼ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    num_months íŒŒë¼ë¯¸í„°ëŠ” ì›”í‰ê·  ê³„ì‚°ì˜ ê¸°ì¤€ì´ ë©ë‹ˆë‹¤.
    """
    if _drive_service is None:
        st.error("ì˜¤ë¥˜: Google Drive ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ë§¤ì¶œ ë°ì´í„° ë¡œë”©)")
        return pd.DataFrame()

    file_bytes_sales = download_excel_from_drive_as_bytes(_drive_service, file_id_sales, f"ë§¤ì¶œë‚´ì—­ ({sheet_name})")
    if file_bytes_sales is None:
        return pd.DataFrame()

    try:
        required_cols = [SALES_DATE_COL, SALES_PROD_CODE_COL, SALES_PROD_NAME_COL,
                         SALES_QTY_BOX_COL, SALES_QTY_KG_COL, SALES_LOCATION_COL]

        df = pd.read_excel(file_bytes_sales, sheet_name=sheet_name)

        if not all(col in df.columns for col in required_cols):
            missing_cols = [col for col in required_cols if col not in df.columns]
            st.error(f"ì˜¤ë¥˜: ë§¤ì¶œ ë‚´ì—­ ì‹œíŠ¸ '{sheet_name}' (ID: {file_id_sales})ì— í•„ìš”í•œ ì»¬ëŸ¼({missing_cols}) ì—†ìŒ")
            st.write(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {df.columns.tolist()}")
            return pd.DataFrame()

        df[SALES_DATE_COL] = pd.to_datetime(df[SALES_DATE_COL], errors='coerce')
        df.dropna(subset=[SALES_DATE_COL], inplace=True)

        if df.empty:
            st.warning(f"ë§¤ì¶œë‚´ì—­ íŒŒì¼ (ID: {file_id_sales}, ì‹œíŠ¸: {sheet_name})ì— ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        df[SALES_PROD_CODE_COL] = df[SALES_PROD_CODE_COL].astype(str).str.strip().str.replace(r'\.0$', '', regex=True)
        df[SALES_PROD_NAME_COL] = df[SALES_PROD_NAME_COL].astype(str).str.strip()
        df[SALES_LOCATION_COL] = df[SALES_LOCATION_COL].astype(str).str.strip()
        df[SALES_QTY_BOX_COL] = pd.to_numeric(df[SALES_QTY_BOX_COL], errors='coerce').fillna(0)
        df[SALES_QTY_KG_COL] = pd.to_numeric(df[SALES_QTY_KG_COL], errors='coerce').fillna(0)

        max_sales_date = df[SALES_DATE_COL].max()
        if pd.isna(max_sales_date):
            st.warning(f"ë§¤ì¶œ ë°ì´í„° (ID: {file_id_sales}, ì‹œíŠ¸: {sheet_name})ì—ì„œ ìœ íš¨í•œ ìµœëŒ€ ë§¤ì¶œì¼ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        end_date_of_analysis_period = max_sales_date
        start_date_of_analysis_period = end_date_of_analysis_period - pd.Timedelta(days=89)

        st.info(f"ë§¤ì¶œ ë¶„ì„ ê¸°ê°„ (ë°ì´í„° ë§ˆì§€ë§‰ ë‚ ì§œ ê¸°ì¤€ 90ì¼): {start_date_of_analysis_period.strftime('%Y-%m-%d')} ~ {end_date_of_analysis_period.strftime('%Y-%m-%d')}")

        df_filtered = df[
            (df[SALES_DATE_COL] >= start_date_of_analysis_period) &
            (df[SALES_DATE_COL] <= end_date_of_analysis_period)
        ].copy()

        if df_filtered.empty:
            st.warning(f"ì„ íƒëœ ê¸°ê°„ ({start_date_of_analysis_period.strftime('%Y-%m-%d')} ~ {end_date_of_analysis_period.strftime('%Y-%m-%d')})ì˜ ë§¤ì¶œ ë°ì´í„°ê°€ '{sheet_name}' ì‹œíŠ¸ì— ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        total_sales_by_item_loc = df_filtered.groupby(
            [SALES_PROD_CODE_COL, SALES_PROD_NAME_COL, SALES_LOCATION_COL],
            as_index=False
        ).agg(
            TotalQtyBox=(SALES_QTY_BOX_COL, 'sum'),
            TotalQtyKg=(SALES_QTY_KG_COL, 'sum'),
            SalesDays=(SALES_DATE_COL, 'nunique')
        )
        return total_sales_by_item_loc
    except ValueError as ve:
        if sheet_name and f"Worksheet named '{sheet_name}' not found" in str(ve):
            st.error(f"ì˜¤ë¥˜: ë§¤ì¶œ íŒŒì¼ (ID: {file_id_sales})ì— '{sheet_name}' ì‹œíŠ¸ ì—†ìŒ")
        else:
            st.error(f"ë§¤ì¶œ ë°ì´í„° (ID: {file_id_sales}, ì‹œíŠ¸: {sheet_name}) ë¡œë“œ ì¤‘ ê°’ ì˜¤ë¥˜: {ve}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"ë§¤ì¶œ ë°ì´í„° (ID: {file_id_sales}, ì‹œíŠ¸: {sheet_name}) ë¡œë“œ/ì²˜ë¦¬ ì¤‘ ì˜ˆìƒ ëª»í•œ ì˜¤ë¥˜: {e}")
        st.error(traceback.format_exc())
        return pd.DataFrame()

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def load_current_stock_data(_drive_service, file_id_sm):
    """SMì¬ê³ í˜„í™© íŒŒì¼ì˜ ìµœì‹  ë‚ ì§œ ì‹œíŠ¸ì—ì„œ í˜„ì¬ê³  ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if _drive_service is None:
        st.error("ì˜¤ë¥˜: Google Drive ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (í˜„ì¬ê³  ë°ì´í„° ë¡œë”©)")
        return pd.DataFrame()

    sm_file_bytes = download_excel_from_drive_as_bytes(_drive_service, file_id_sm, "SMì¬ê³ í˜„í™© (í˜„ì¬ê³  ì¡°íšŒìš©)")
    if not sm_file_bytes:
        return pd.DataFrame()

    available_sm_dates = get_all_available_sheet_dates_from_bytes(sm_file_bytes, "SMì¬ê³ í˜„í™© (í˜„ì¬ê³  ì¡°íšŒìš©)")
    if not available_sm_dates:
        st.warning(f"SMì¬ê³ í˜„í™© íŒŒì¼ (ID: {file_id_sm})ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì¬ê³  ë°ì´í„° ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    latest_date_obj = available_sm_dates[0]
    latest_date_str = latest_date_obj.strftime("%Y%m%d")
    st.info(f"í˜„ì¬ê³  ê¸°ì¤€ì¼: {latest_date_obj.strftime('%Y-%m-%d')} (ì‹œíŠ¸: {latest_date_str})")

    try:
        sm_file_bytes.seek(0)
        df_stock_raw = pd.read_excel(sm_file_bytes, sheet_name=latest_date_str)

        required_stock_cols = [CURRENT_STOCK_PROD_CODE_COL, CURRENT_STOCK_PROD_NAME_COL,
                               CURRENT_STOCK_QTY_COL, CURRENT_STOCK_WGT_COL, CURRENT_STOCK_LOCATION_COL]
<<<<<<< HEAD
=======
        df_stock_raw.rename(columns={'ìƒ í’ˆ ëª…': 'ìƒí’ˆëª…'}, inplace=True)
>>>>>>> 46ccaad40de1fda1a1b06e92242795ac69bdc0f3

        if not all(col in df_stock_raw.columns for col in required_stock_cols):
            missing = [col for col in required_stock_cols if col not in df_stock_raw.columns]
            st.error(f"í˜„ì¬ê³  ë°ì´í„° ì‹œíŠ¸('{latest_date_str}', ID: {file_id_sm})ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}.")
            st.error("ì½”ë“œ ìƒë‹¨ì˜ í˜„ì¬ê³  ê´€ë ¨ ìƒìˆ˜(CURRENT_STOCK_..._COL)ì™€ ì‹¤ì œ ì—‘ì…€ íŒŒì¼ì˜ ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()

        df_stock_raw[CURRENT_STOCK_PROD_CODE_COL] = df_stock_raw[CURRENT_STOCK_PROD_CODE_COL].astype(str).str.strip().str.replace(r'\.0$', '', regex=True)
        df_stock_raw[CURRENT_STOCK_PROD_NAME_COL] = df_stock_raw[CURRENT_STOCK_PROD_NAME_COL].astype(str).str.strip()
        df_stock_raw[CURRENT_STOCK_LOCATION_COL] = df_stock_raw[CURRENT_STOCK_LOCATION_COL].astype(str).str.strip()
        df_stock_raw[CURRENT_STOCK_QTY_COL] = pd.to_numeric(df_stock_raw[CURRENT_STOCK_QTY_COL], errors='coerce').fillna(0)
        df_stock_raw[CURRENT_STOCK_WGT_COL] = pd.to_numeric(df_stock_raw[CURRENT_STOCK_WGT_COL], errors='coerce').fillna(0)

        current_stock_by_item_loc = df_stock_raw.groupby(
            [CURRENT_STOCK_PROD_CODE_COL, CURRENT_STOCK_PROD_NAME_COL, CURRENT_STOCK_LOCATION_COL],
            as_index=False
        ).agg(
            CurrentQty=(CURRENT_STOCK_QTY_COL, 'sum'),
            CurrentWgt=(CURRENT_STOCK_WGT_COL, 'sum')
        )

        if current_stock_by_item_loc.empty and not df_stock_raw.empty:
            st.warning(f"í˜„ì¬ê³  ë°ì´í„° ê·¸ë£¹í•‘ í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (ì‹œíŠ¸: {latest_date_str}, ID: {file_id_sm}). ì»¬ëŸ¼ëª… ë˜ëŠ” ë°ì´í„° ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return pd.DataFrame()
        return current_stock_by_item_loc
    except ValueError as ve:
        if latest_date_str and f"Worksheet named '{latest_date_str}' not found" in str(ve):
            st.error(f"ì˜¤ë¥˜: í˜„ì¬ê³  íŒŒì¼ (ID: {file_id_sm})ì— '{latest_date_str}' ì‹œíŠ¸ ì—†ìŒ")
        else:
            st.error(f"í˜„ì¬ê³  ë°ì´í„° (ID: {file_id_sm}, ì‹œíŠ¸: {latest_date_str}) ë¡œë“œ ì¤‘ ê°’ ì˜¤ë¥˜: {ve}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"í˜„ì¬ê³  ë°ì´í„° (ID: {file_id_sm}, ì‹œíŠ¸: {latest_date_str}) ë¡œë“œ/ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        st.error(traceback.format_exc())
        return pd.DataFrame()

<<<<<<< HEAD
# --- (ê¸°ëŠ¥ ì¶”ê°€) íŠ¹ì • í’ˆëª©ì˜ ì¬ê³  ë³€ë™ ë‚´ì—­ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ ---
@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def get_stock_history_for_item(_drive_service, file_id_sm, search_term):
    """SMì¬ê³ í˜„í™© íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ë¥¼ ì½ì–´ íŠ¹ì • ìƒí’ˆì˜ 90ì¼ê°„ ì¬ê³  ì¶”ì´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if _drive_service is None:
        st.error("ì˜¤ë¥˜: Google Drive ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(), None, None

    sm_file_bytes = download_excel_from_drive_as_bytes(_drive_service, file_id_sm, "SMì¬ê³ í˜„í™© (ì¬ê³  ì¶”ì´ ì¡°íšŒìš©)")
    if not sm_file_bytes:
        st.error("SMì¬ê³ í˜„í™© íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(), None, None

    try:
        xls = pd.ExcelFile(sm_file_bytes)
        all_sheets = xls.sheet_names
        sheet_dates = []
        for sheet in all_sheets:
            try:
                sheet_dates.append(datetime.datetime.strptime(sheet, "%Y%m%d"))
            except ValueError:
                continue

        sheet_dates.sort(reverse=True)
        today = datetime.datetime.now().date()
        ninety_days_ago = today - datetime.timedelta(days=90)
        
        relevant_sheets = [dt.strftime("%Y%m%d") for dt in sheet_dates if ninety_days_ago <= dt.date() <= today]

        if not relevant_sheets:
            st.warning("ì§€ë‚œ 90ì¼ê°„ì˜ ì¬ê³  ë°ì´í„° ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame(), None, None
    except Exception as e:
        st.error(f"SMì¬ê³ í˜„í™© íŒŒì¼ì˜ ì‹œíŠ¸ë¥¼ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame(), None, None

    is_code_search = search_term.isdigit()
    history = []
    found_product_name = ""
    found_product_code = ""

    for sheet_name in relevant_sheets:
        try:
            df_stock_raw = pd.read_excel(xls, sheet_name=sheet_name)

            df_stock_raw[CURRENT_STOCK_PROD_CODE_COL] = df_stock_raw[CURRENT_STOCK_PROD_CODE_COL].astype(str).str.strip().str.replace(r'\.0$', '', regex=True)
            df_stock_raw[CURRENT_STOCK_PROD_NAME_COL] = df_stock_raw[CURRENT_STOCK_PROD_NAME_COL].astype(str).str.strip()
            df_stock_raw[CURRENT_STOCK_QTY_COL] = pd.to_numeric(df_stock_raw[CURRENT_STOCK_QTY_COL], errors='coerce').fillna(0)

            if is_code_search:
                filtered_df = df_stock_raw[df_stock_raw[CURRENT_STOCK_PROD_CODE_COL] == search_term].copy()
            else:
                filtered_df = df_stock_raw[df_stock_raw[CURRENT_STOCK_PROD_NAME_COL].str.contains(search_term, na=False)].copy()

            total_stock = filtered_df[CURRENT_STOCK_QTY_COL].sum()
            sheet_date = datetime.datetime.strptime(sheet_name, "%Y%m%d").date()
            history.append({'ì¼ì': sheet_date, 'ì¬ê³ ëŸ‰(ë°•ìŠ¤)': total_stock})
            
            if not found_product_name and not filtered_df.empty:
                 # ê²€ìƒ‰ ê²°ê³¼ì˜ ì²«ë²ˆì§¸ í•­ëª©ìœ¼ë¡œ ìƒí’ˆì •ë³´ë¥¼ ì„¤ì •
                found_product_name = filtered_df.iloc[0][CURRENT_STOCK_PROD_NAME_COL]
                found_product_code = filtered_df.iloc[0][CURRENT_STOCK_PROD_CODE_COL]

        except Exception:
            continue # íŠ¹ì • ì‹œíŠ¸ ì½ê¸° ì‹¤íŒ¨ ì‹œ ê±´ë„ˆë›°ê¸°

    if not history:
        st.warning(f"'{search_term}'ì— ëŒ€í•œ ì§€ë‚œ 90ì¼ê°„ì˜ ì¬ê³  ê¸°ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(), None, None

    history_df = pd.DataFrame(history).sort_values(by='ì¼ì').reset_index(drop=True)
    return history_df, found_product_code, found_product_name
# --- í•¨ìˆ˜ ì¶”ê°€ ë ---
=======
# --- ì¬ê³  ì¶”ì´ ë¶„ì„ì„ ìœ„í•œ í•¨ìˆ˜ë“¤ ---

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def find_matching_products(_drive_service, file_id_sm, search_term):
    """ê°€ì¥ ìµœì‹  ì¬ê³  ì‹œíŠ¸ì—ì„œ ê²€ìƒ‰ì–´ì™€ ì¼ì¹˜í•˜ëŠ” ëª¨ë“  í’ˆëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    if _drive_service is None: return []
    sm_file_bytes = download_excel_from_drive_as_bytes(_drive_service, file_id_sm, "SMì¬ê³ í˜„í™© (í’ˆëª© ê²€ìƒ‰ìš©)")
    if not sm_file_bytes: return []

    available_sm_dates = get_all_available_sheet_dates_from_bytes(sm_file_bytes, "SMì¬ê³ í˜„í™© (í’ˆëª© ê²€ìƒ‰ìš©)")
    if not available_sm_dates: return []
    
    latest_date_str = available_sm_dates[0].strftime("%Y%m%d")
    try:
        sm_file_bytes.seek(0)
        df = pd.read_excel(sm_file_bytes, sheet_name=latest_date_str)
        df.rename(columns={'ìƒ í’ˆ ëª…': 'ìƒí’ˆëª…'}, inplace=True) # ì»¬ëŸ¼ëª… ì˜¤íƒ€ ëŒ€ì‘

        df[CURRENT_STOCK_PROD_CODE_COL] = df[CURRENT_STOCK_PROD_CODE_COL].astype(str).str.strip().str.replace(r'\.0$', '', regex=True)
        df[CURRENT_STOCK_PROD_NAME_COL] = df[CURRENT_STOCK_PROD_NAME_COL].astype(str).str.strip()
        
        if search_term.isdigit():
            matches = df[df[CURRENT_STOCK_PROD_CODE_COL] == search_term]
        else:
            matches = df[df[CURRENT_STOCK_PROD_NAME_COL].str.contains(search_term, na=False)]
        
        if matches.empty:
            return []
            
        unique_products = matches[[CURRENT_STOCK_PROD_CODE_COL, CURRENT_STOCK_PROD_NAME_COL]].drop_duplicates().values.tolist()
        return [tuple(prod) for prod in unique_products]
    except Exception:
        return []

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def get_stock_history_for_item_by_code(_drive_service, file_id_sm, product_code):
    """íŠ¹ì • 'ìƒí’ˆì½”ë“œ'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 90ì¼ê°„ì˜ ì¬ê³  ì¶”ì´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if not _drive_service or not product_code:
        return pd.DataFrame()

    sm_file_bytes = download_excel_from_drive_as_bytes(_drive_service, file_id_sm, "SMì¬ê³ í˜„í™© (ì¬ê³  ì¶”ì´ ì¡°íšŒìš©)")
    if not sm_file_bytes: return pd.DataFrame()
    
    try:
        xls = pd.ExcelFile(sm_file_bytes)
        all_sheets = xls.sheet_names
        sheet_dates = sorted([datetime.datetime.strptime(s, "%Y%m%d") for s in all_sheets if s.isdigit()], reverse=True)
        
        today = datetime.datetime.now().date()
        ninety_days_ago = today - datetime.timedelta(days=90)
        relevant_sheets = [dt.strftime("%Y%m%d") for dt in sheet_dates if ninety_days_ago <= dt.date() <= today]

        history = []
        for sheet_name in relevant_sheets:
            df_stock_raw = pd.read_excel(xls, sheet_name=sheet_name)
            df_stock_raw.rename(columns={'ìƒ í’ˆ ëª…': 'ìƒí’ˆëª…'}, inplace=True)
            df_stock_raw[CURRENT_STOCK_PROD_CODE_COL] = df_stock_raw[CURRENT_STOCK_PROD_CODE_COL].astype(str).str.strip().str.replace(r'\.0$', '', regex=True)
            df_stock_raw[CURRENT_STOCK_QTY_COL] = pd.to_numeric(df_stock_raw[CURRENT_STOCK_QTY_COL], errors='coerce').fillna(0)
            
            filtered_df = df_stock_raw[df_stock_raw[CURRENT_STOCK_PROD_CODE_COL] == product_code]
            total_stock = filtered_df[CURRENT_STOCK_QTY_COL].sum()
            sheet_date = datetime.datetime.strptime(sheet_name, "%Y%m%d").date()
            history.append({'ì¼ì': sheet_date, 'ì¬ê³ ëŸ‰(ë°•ìŠ¤)': total_stock})

        if not history: return pd.DataFrame()
        return pd.DataFrame(history).sort_values(by='ì¼ì').reset_index(drop=True)
    except Exception:
        return pd.DataFrame()
>>>>>>> 46ccaad40de1fda1a1b06e92242795ac69bdc0f3


# --- Streamlit í˜ì´ì§€ UI ë° ë¡œì§ ---
st.title("ğŸ“¦ ì¬ê³  ë³´ì¶© ì œì•ˆ ë³´ê³ ì„œ (ì§€ì ë³„)")

if drive_service is None:
    st.error("Google Drive ì„œë¹„ìŠ¤ì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•±ì˜ ë©”ì¸ í˜ì´ì§€ë¥¼ ë°©ë¬¸í•˜ì—¬ ì¸ì¦ì„ ì™„ë£Œí•˜ê±°ë‚˜, ì•± ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

MIN_SALES_DAYS_PER_MONTH = 5
st.markdown(f"""
ìµœê·¼ 90ì¼ê°„ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›”í‰ê·  ì¶œê³ ëŸ‰ê³¼ í˜„ì¬ê³ ë¥¼ **ì§€ì ë³„ë¡œ** ë¹„êµí•˜ì—¬ ë³´ì¶© í•„ìš” ìˆ˜ëŸ‰ì„ ì œì•ˆí•©ë‹ˆë‹¤.
(ì—¬ê¸°ì„œ 'ì›”í‰ê· 'ì€ 90ì¼ê°„ ì´ ì¶œê³ ëŸ‰ì„ 3ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ê³„ì‚°í•©ë‹ˆë‹¤.)
**ë‹¨, (90ì¼ ê¸°ì¤€) ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜ê°€ {MIN_SALES_DAYS_PER_MONTH}ì¼ ì´ìƒì´ê³ , ê³„ì‚°ëœ í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)ì´ 0ë³´ë‹¤ í° í’ˆëª©ë§Œ ëŒ€ìƒ**ìœ¼ë¡œ í•©ë‹ˆë‹¤.
""")

st.markdown(f"ë§¤ì¶œ ë°ì´í„° ì›ë³¸: Google Drive íŒŒì¼ (ID: `{SALES_FILE_ID}`)ì˜ '{SALES_DATA_SHEET_NAME}' ì‹œíŠ¸")
st.markdown(f"í˜„ì¬ê³  ë°ì´í„° ì›ë³¸: Google Drive íŒŒì¼ (ID: `{SM_FILE_ID}`)ì˜ ìµœì‹  ë‚ ì§œ ì‹œíŠ¸")
st.markdown("---")

<<<<<<< HEAD
# --- ê¸°ì¡´ ì¬ê³  ë³´ì¶© ì œì•ˆ ë¡œì§ (ìˆ˜ì • ì—†ìŒ) ---
# (ì´ ë¶€ë¶„ì€ ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•©ë‹ˆë‹¤)
=======
>>>>>>> 46ccaad40de1fda1a1b06e92242795ac69bdc0f3
num_months_to_analyze = 3
df_total_sales_90d = load_sales_history_and_filter_3m(drive_service, SALES_FILE_ID, SALES_DATA_SHEET_NAME, num_months=num_months_to_analyze)
df_current_stock = load_current_stock_data(drive_service, SM_FILE_ID)

if df_total_sales_90d.empty or df_current_stock.empty:
    st.warning("ë§¤ì¶œ ë°ì´í„° ë˜ëŠ” í˜„ì¬ê³  ë°ì´í„°ê°€ ì—†ì–´ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ ë¡œê·¸ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    df_avg_monthly_sales = df_total_sales_90d.copy()
    df_avg_monthly_sales['ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)'] = (df_avg_monthly_sales['TotalQtyBox'] / num_months_to_analyze).round(2)
    df_avg_monthly_sales['ì›”í‰ê·  ì¶œê³ ëŸ‰(Kg)'] = (df_avg_monthly_sales['TotalQtyKg'] / num_months_to_analyze).round(2)
    df_avg_monthly_sales['ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜'] = (df_avg_monthly_sales['SalesDays'] / num_months_to_analyze).round(2)

    df_avg_monthly_sales_filtered = df_avg_monthly_sales[df_avg_monthly_sales['ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜'] >= MIN_SALES_DAYS_PER_MONTH].copy()

    if df_avg_monthly_sales_filtered.empty:
        st.warning(f"ê³„ì‚°ëœ ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜ê°€ {MIN_SALES_DAYS_PER_MONTH}ì¼ ì´ìƒì¸ í’ˆëª©ì´ ì—†ìŠµë‹ˆë‹¤. ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.success(f"ì´ {len(df_avg_monthly_sales)}ê°œ í’ˆëª©(ì§€ì ë³„, 90ì¼ ê¸°ì¤€) ì¤‘ ê³„ì‚°ëœ ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜ {MIN_SALES_DAYS_PER_MONTH}ì¼ ì´ìƒì¸ {len(df_avg_monthly_sales_filtered)}ê°œ í’ˆëª©ì„ ëŒ€ìƒìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
    
        df_avg_monthly_sales_to_use = df_avg_monthly_sales_filtered.rename(columns={
<<<<<<< HEAD
            SALES_PROD_CODE_COL: 'ìƒí’ˆì½”ë“œ',
=======
            SALES_PROD_CODE_COL: 'ìƒí’ˆì½”ë“œ', 
>>>>>>> 46ccaad40de1fda1a1b06e92242795ac69bdc0f3
            SALES_PROD_NAME_COL: 'ìƒí’ˆëª…',
            SALES_LOCATION_COL: 'ì§€ì ëª…'
        })
        df_avg_monthly_sales_to_use['ìƒí’ˆì½”ë“œ'] = df_avg_monthly_sales_to_use['ìƒí’ˆì½”ë“œ'].astype(str).str.strip().str.replace(r'\.0$', '', regex=True)
        df_avg_monthly_sales_to_use['ì§€ì ëª…'] = df_avg_monthly_sales_to_use['ì§€ì ëª…'].astype(str).str.strip()
        df_avg_monthly_sales_to_use = df_avg_monthly_sales_to_use[['ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…', 'ì§€ì ëª…', 'ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)', 'ì›”í‰ê·  ì¶œê³ ëŸ‰(Kg)', 'ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜']]

        df_current_stock_report = df_current_stock.rename(columns={
            CURRENT_STOCK_PROD_CODE_COL: 'ìƒí’ˆì½”ë“œ',
<<<<<<< HEAD
            CURRENT_STOCK_PROD_NAME_COL: 'ìƒí’ˆëª…',
=======
            CURRENT_STOCK_PROD_NAME_COL: 'ìƒí’ˆëª…', 
>>>>>>> 46ccaad40de1fda1a1b06e92242795ac69bdc0f3
            CURRENT_STOCK_LOCATION_COL: 'ì§€ì ëª…',
            'CurrentQty': 'ì”ëŸ‰(ë°•ìŠ¤)',
            'CurrentWgt': 'ì”ëŸ‰(Kg)'
        })
        df_current_stock_report['ìƒí’ˆì½”ë“œ'] = df_current_stock_report['ìƒí’ˆì½”ë“œ'].astype(str).str.strip().str.replace(r'\.0$', '', regex=True)
        df_current_stock_report['ì§€ì ëª…'] = df_current_stock_report['ì§€ì ëª…'].astype(str).str.strip()
        df_current_stock_report = df_current_stock_report[['ìƒí’ˆì½”ë“œ', 'ì§€ì ëª…', 'ìƒí’ˆëª…', 'ì”ëŸ‰(ë°•ìŠ¤)', 'ì”ëŸ‰(Kg)']]

        df_report = pd.merge(
<<<<<<< HEAD
            df_avg_monthly_sales_to_use,
            df_current_stock_report,
            on=['ìƒí’ˆì½”ë“œ', 'ì§€ì ëª…'],
            how='left',
            suffixes=('_sales', '_stock')
        )

        df_report['ìƒí’ˆëª…'] = df_report['ìƒí’ˆëª…_sales'].fillna(df_report['ìƒí’ˆëª…_stock'])
        df_report.drop(columns=['ìƒí’ˆëª…_sales', 'ìƒí’ˆëª…_stock'], inplace=True, errors='ignore')

=======
            df_avg_monthly_sales_to_use, 
            df_current_stock_report, 
            on=['ìƒí’ˆì½”ë“œ', 'ì§€ì ëª…'], 
            how='left', 
            suffixes=('_sales', '_stock') 
        )
        
        df_report['ìƒí’ˆëª…'] = df_report['ìƒí’ˆëª…_sales'].fillna(df_report['ìƒí’ˆëª…_stock'])
        df_report.drop(columns=['ìƒí’ˆëª…_sales', 'ìƒí’ˆëª…_stock'], inplace=True, errors='ignore') 
        
>>>>>>> 46ccaad40de1fda1a1b06e92242795ac69bdc0f3
        df_report['ì”ëŸ‰(ë°•ìŠ¤)'] = df_report['ì”ëŸ‰(ë°•ìŠ¤)'].fillna(0)
        df_report['ì”ëŸ‰(Kg)'] = df_report['ì”ëŸ‰(Kg)'].fillna(0)

        df_report['í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)'] = (df_report['ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)'] - df_report['ì”ëŸ‰(ë°•ìŠ¤)']).apply(lambda x: max(0, x)).round(2)
        df_report['í•„ìš”ìˆ˜ëŸ‰(Kg)'] = (df_report['ì›”í‰ê·  ì¶œê³ ëŸ‰(Kg)'] - df_report['ì”ëŸ‰(Kg)']).apply(lambda x: max(0, x)).round(2)
<<<<<<< HEAD

=======
        
>>>>>>> 46ccaad40de1fda1a1b06e92242795ac69bdc0f3
        df_report_filtered_needed = df_report[df_report['í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)'] > 0].copy()

        if df_report_filtered_needed.empty:
            st.info(f"ê³„ì‚°ëœ ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜ {MIN_SALES_DAYS_PER_MONTH}ì¼ ì´ìƒì¸ í’ˆëª© ì¤‘ í˜„ì¬ ë³´ì¶©ì´ í•„ìš”í•œ í’ˆëª©(í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤) > 0)ì€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            final_report_columns = [
<<<<<<< HEAD
                'ì§€ì ëª…', 'ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…',
                'ì”ëŸ‰(ë°•ìŠ¤)', 'ì”ëŸ‰(Kg)',
                'ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)', 'ì›”í‰ê·  ì¶œê³ ëŸ‰(Kg)',
                'ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜',
                'í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)', 'í•„ìš”ìˆ˜ëŸ‰(Kg)'
            ]
            existing_final_cols = [col for col in final_report_columns if col in df_report_filtered_needed.columns]
            df_report_final = df_report_filtered_needed[existing_final_cols]
=======
                'ì§€ì ëª…', 'ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…', 
                'ì”ëŸ‰(ë°•ìŠ¤)', 'ì”ëŸ‰(Kg)', 
                'ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)', 'ì›”í‰ê·  ì¶œê³ ëŸ‰(Kg)',
                'ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜', 
                'í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)', 'í•„ìš”ìˆ˜ëŸ‰(Kg)'
            ]
            existing_final_cols = [col for col in final_report_columns if col in df_report_filtered_needed.columns] 
            df_report_final = df_report_filtered_needed[existing_final_cols]

>>>>>>> 46ccaad40de1fda1a1b06e92242795ac69bdc0f3
            df_report_final = df_report_final.sort_values(by=['ì§€ì ëª…', 'í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)'], ascending=[True, False])

            st.markdown("---")
            st.header("ğŸ“‹ ì¬ê³  ë³´ì¶© ì œì•ˆ ë¦¬ìŠ¤íŠ¸ (ì§€ì ë³„)")
<<<<<<< HEAD

            df_display = df_report_final.copy()

            if 'ìƒí’ˆì½”ë“œ' in df_display.columns:
                try:
                    df_display['ìƒí’ˆì½”ë“œ'] = df_display['ìƒí’ˆì½”ë“œ'].astype(str).str.replace(r'\.0$', '', regex=True)
                except Exception as e_strip:
                    st.warning(f"ìƒí’ˆì½”ë“œ ë¬¸ìì—´ ë³€í™˜ ì¤‘ ê²½ë¯¸í•œ ì˜¤ë¥˜: {e_strip}")
                    df_display['ìƒí’ˆì½”ë“œ'] = df_display['ìƒí’ˆì½”ë“œ'].astype(str)
=======
            
            df_display = df_report_final.copy() 

            if 'ìƒí’ˆì½”ë“œ' in df_display.columns:
                try: 
                    df_display['ìƒí’ˆì½”ë“œ'] = df_display['ìƒí’ˆì½”ë“œ'].astype(str).str.replace(r'\.0$', '', regex=True)
                except Exception as e_strip:
                    st.warning(f"ìƒí’ˆì½”ë“œ ë¬¸ìì—´ ë³€í™˜ ì¤‘ ê²½ë¯¸í•œ ì˜¤ë¥˜: {e_strip}")
                    df_display['ìƒí’ˆì½”ë“œ'] = df_display['ìƒí’ˆì½”ë“œ'].astype(str) 
>>>>>>> 46ccaad40de1fda1a1b06e92242795ac69bdc0f3

            cols_to_make_int_for_display = ['ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)', 'í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)', 'ì”ëŸ‰(ë°•ìŠ¤)']
            for col in cols_to_make_int_for_display:
                if col in df_display.columns:
                    df_display[col] = pd.to_numeric(df_display[col], errors='coerce').fillna(0).round(0).astype('Int64')

            format_dict = {}
            for col in ['ì”ëŸ‰(ë°•ìŠ¤)', 'ì›”í‰ê·  ì¶œê³ ëŸ‰(ë°•ìŠ¤)', 'í•„ìš”ìˆ˜ëŸ‰(ë°•ìŠ¤)']:
<<<<<<< HEAD
                if col in df_display.columns:
                    format_dict[col] = "{:,.0f}"

            for col in ['ì”ëŸ‰(Kg)', 'ì›”í‰ê·  ì¶œê³ ëŸ‰(Kg)', 'í•„ìš”ìˆ˜ëŸ‰(Kg)']:
                if col in df_display.columns:
                    format_dict[col] = "{:,.2f}"

            if 'ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜' in df_display.columns:
                format_dict['ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜'] = "{:,.2f}"

=======
                if col in df_display.columns: 
                    format_dict[col] = "{:,.0f}" 
            
            for col in ['ì”ëŸ‰(Kg)', 'ì›”í‰ê·  ì¶œê³ ëŸ‰(Kg)', 'í•„ìš”ìˆ˜ëŸ‰(Kg)']:
                if col in df_display.columns: 
                    format_dict[col] = "{:,.2f}" 
            
            if 'ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜' in df_display.columns: 
                format_dict['ì›”í‰ê·  ì¶œê³ ì¼ìˆ˜'] = "{:,.2f}"
                
>>>>>>> 46ccaad40de1fda1a1b06e92242795ac69bdc0f3
            def highlight_refrigerated_product_name(val):
                if isinstance(val, str) and "ëƒ‰ì¥" in val:
                    return 'color: red'
                return ''

            st.dataframe(
                df_display.style.format(format_dict, na_rep="-")
                .map(highlight_refrigerated_product_name, subset=['ìƒí’ˆëª…'])
<<<<<<< HEAD
                .set_properties(**{'text-align': 'right'}),
                use_container_width=True
            )

            @st.cache_data
            def convert_df_to_excel(df_to_convert):
                excel_stream = io.BytesIO()
                with pd.ExcelWriter(excel_stream, engine='xlsxwriter') as writer:
                    df_to_convert.to_excel(writer, index=False, sheet_name='ë³´ê³ ì„œ')
                excel_stream.seek(0)
=======
                .set_properties(**{'text-align': 'right'}), 
                use_container_width=True
            )

            @st.cache_data 
            def convert_df_to_excel(df_to_convert):
                excel_stream = io.BytesIO()
                with pd.ExcelWriter(excel_stream, engine='xlsxwriter') as writer: 
                    df_to_convert.to_excel(writer, index=False, sheet_name='ë³´ê³ ì„œ')
                excel_stream.seek(0) 
>>>>>>> 46ccaad40de1fda1a1b06e92242795ac69bdc0f3
                return excel_stream.getvalue()

            if not df_display.empty:
                excel_data = convert_df_to_excel(df_display)
                report_date_str = datetime.date.today().strftime("%Y%m%d")
                st.download_button(
                    label="ğŸ“¥ ë³´ê³ ì„œ ì—‘ì…€ë¡œ ë‹¤ìš´ë¡œë“œ",
                    data=excel_data,
                    file_name=f"ì¬ê³ ë³´ì¶©ì œì•ˆë³´ê³ ì„œ_ì§€ì ë³„_{report_date_str}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
<<<<<<< HEAD
                    key="download_replenishment_report_formatted_page_filtered_no_zero_needed_v3"
                )

# --- (ê¸°ëŠ¥ ì¶”ê°€) ê°œë³„ í’ˆëª© ì¬ê³  ì¶”ì´ ì¡°íšŒ UI ---
st.markdown("---")
st.header("ğŸ” ê°œë³„ í’ˆëª© ì¬ê³  ì¶”ì´ ì¡°íšŒ")

search_term = st.text_input("ì¡°íšŒí•  ìƒí’ˆì˜ ìƒí’ˆì½”ë“œ ë˜ëŠ” ìƒí’ˆëª…ì„ ì…ë ¥í•˜ì„¸ìš”:", key="stock_trace_search_input")

if st.button("ì¬ê³  ì¶”ì´ ì¡°íšŒ", key="stock_trace_search_button"):
    if not search_term.strip():
        st.warning("ìƒí’ˆì½”ë“œ ë˜ëŠ” ìƒí’ˆëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner(f"'{search_term}'ì— ëŒ€í•œ ì¬ê³  ê¸°ë¡ì„ ì¡°íšŒí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            history_df, p_code, p_name = get_stock_history_for_item(drive_service, SM_FILE_ID, search_term.strip())

        if not history_df.empty:
            st.success(f"**{p_name} (ì½”ë“œ: {p_code})** ì¬ê³  ë³€ë™ ë‚´ì—­")

            # 1. 1ì£¼ì¼ê°„ì˜ ì¼ë³„ ì¬ê³  ë³€ë™ (í‘œ)
            st.subheader("ğŸ—“ï¸ ìµœê·¼ 1ì£¼ì¼ ì¬ê³  ë³€ë™")
            one_week_ago = datetime.datetime.now().date() - datetime.timedelta(days=7)
            history_df['ì¼ì_dt'] = pd.to_datetime(history_df['ì¼ì']).dt.date
            
            weekly_df = history_df[history_df['ì¼ì_dt'] >= one_week_ago].copy()
            weekly_df['ì¼ì'] = weekly_df['ì¼ì'].apply(lambda x: x.strftime('%Y-%m-%d (%a)'))
            
            st.dataframe(weekly_df[['ì¼ì', 'ì¬ê³ ëŸ‰(ë°•ìŠ¤)']].style.format({'ì¬ê³ ëŸ‰(ë°•ìŠ¤)': "{:,.0f}"}), use_container_width=True)

            # 2. 3ê°œì›” ë™ì•ˆì˜ ì¬ê³  ë³€ë™ (ê·¸ë˜í”„)
            st.subheader("ğŸ“ˆ ìµœê·¼ 3ê°œì›” ì¬ê³  ë³€ë™ ê·¸ë˜í”„")
            
            fig = px.line(history_df, x='ì¼ì', y='ì¬ê³ ëŸ‰(ë°•ìŠ¤)', title=f'{p_name} ì¬ê³  ë³€ë™ ì¶”ì´ (90ì¼)', markers=True)
            fig.update_layout(
                xaxis_title='ì¼ì',
                yaxis_title='ì¬ê³ ëŸ‰(ë°•ìŠ¤)',
                yaxis_tickformat=','
            )
            st.plotly_chart(fig, use_container_width=True)
# --- UI ì¶”ê°€ ë ---
=======
                    key="download_replenishment_report_formatted_page_filtered_no_zero_needed_v3" 
                )

# --- ê°œë³„ í’ˆëª© ì¬ê³  ì¶”ì´ ì¡°íšŒ UI ---
st.markdown("---")
st.header("ğŸ” ê°œë³„ í’ˆëª© ì¬ê³  ì¶”ì´ ì¡°íšŒ")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'product_choices' not in st.session_state:
    st.session_state.product_choices = None
if 'selected_product' not in st.session_state:
    st.session_state.selected_product = None

search_term = st.text_input("ì¡°íšŒí•  ìƒí’ˆì˜ ìƒí’ˆì½”ë“œ ë˜ëŠ” ìƒí’ˆëª…ì„ ì…ë ¥í•˜ì„¸ìš”:", key="stock_trace_search_input")

if st.button("í’ˆëª© ê²€ìƒ‰", key="stock_trace_search_button"):
    # ë²„íŠ¼ì„ ëˆ„ë¥¼ ë•Œë§ˆë‹¤ ì´ì „ ì„ íƒ ìƒíƒœë¥¼ ì´ˆê¸°í™”
    st.session_state.product_choices = None
    st.session_state.selected_product = None
    if search_term.strip():
        with st.spinner("ì¼ì¹˜í•˜ëŠ” í’ˆëª©ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
            choices = find_matching_products(drive_service, SM_FILE_ID, search_term.strip())
            if choices:
                st.session_state.product_choices = choices
            else:
                st.warning("ì¼ì¹˜í•˜ëŠ” í’ˆëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("ìƒí’ˆì½”ë“œ ë˜ëŠ” ìƒí’ˆëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# ê²€ìƒ‰ ê²°ê³¼ê°€ ì„¸ì…˜ì— ì €ì¥ë˜ì–´ ìˆì„ ê²½ìš° ì„ íƒ UIë¥¼ í‘œì‹œ
if st.session_state.product_choices:
    choices = st.session_state.product_choices
    if len(choices) == 1:
        # ê²€ìƒ‰ ê²°ê³¼ê°€ í•˜ë‚˜ë¿ì´ë©´ ìë™ìœ¼ë¡œ ì„ íƒ
        st.session_state.selected_product = choices[0]
        # ì‚¬ìš©ìì—ê²Œ ìë™ ì„ íƒë˜ì—ˆìŒì„ ì•Œë¦¼
        st.info(f"ìœ ì¼í•œ í’ˆëª© **{choices[0][1]}** ì´(ê°€) ìë™ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—¬ëŸ¬ ê°œì´ë©´ ì‚¬ìš©ìì—ê²Œ ì„ íƒì§€ë¥¼ ì œê³µ
        display_choices = ["ì•„ë˜ ëª©ë¡ì—ì„œ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”..."] + choices
        
        selected = st.selectbox(
            label="ì—¬ëŸ¬ í’ˆëª©ì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì¡°íšŒí•  í’ˆëª©ì„ ì„ íƒí•˜ì„¸ìš”.",
            options=display_choices,
            format_func=lambda x: x if isinstance(x, str) else f"{x[1]} ({x[0]})"
        )
        if isinstance(selected, tuple): # ì‚¬ìš©ìê°€ ìœ íš¨í•œ í’ˆëª©ì„ ì„ íƒí•œ ê²½ìš°
            st.session_state.selected_product = selected
        else:
            st.session_state.selected_product = None # "ì„ íƒí•˜ì„¸ìš”"ë¥¼ ê³ ë¥¸ ê²½ìš° ì„ íƒ í•´ì œ

# ìµœì¢… í’ˆëª©ì´ ì„ íƒë˜ì—ˆì„ ë•Œë§Œ ì¬ê³  ì¶”ì´ ë¶„ì„ì„ ì‹¤í–‰
if st.session_state.selected_product:
    p_code, p_name = st.session_state.selected_product
    with st.spinner(f"**{p_name}**ì˜ ì¬ê³  ê¸°ë¡ì„ ì¡°íšŒí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        # ìƒí’ˆëª…ì„ ì¸ìë¡œ ë„˜ê¸°ì§€ ì•Šë„ë¡ ìˆ˜ì •
        history_df = get_stock_history_for_item_by_code(drive_service, SM_FILE_ID, p_code)

    if not history_df.empty:
        st.success(f"**{p_name} (ì½”ë“œ: {p_code})** ì¬ê³  ë³€ë™ ë‚´ì—­")

        # 1. 1ì£¼ì¼ê°„ì˜ ì¼ë³„ ì¬ê³  ë³€ë™ (í‘œ)
        st.subheader("ğŸ—“ï¸ ìµœê·¼ 1ì£¼ì¼ ì¬ê³  ë³€ë™")
        one_week_ago = datetime.datetime.now().date() - datetime.timedelta(days=7)
        history_df['ì¼ì_dt'] = pd.to_datetime(history_df['ì¼ì']).dt.date
        
        weekly_df = history_df[history_df['ì¼ì_dt'] > one_week_ago].copy()
        weekly_df['ì¼ì'] = weekly_df['ì¼ì'].apply(lambda x: x.strftime('%Y-%m-%d (%a)'))
        
        st.dataframe(
            weekly_df[['ì¼ì', 'ì¬ê³ ëŸ‰(ë°•ìŠ¤)']].set_index('ì¼ì').style.format({'ì¬ê³ ëŸ‰(ë°•ìŠ¤)': "{:,.0f}"}),
            use_container_width=True
        )

        # 2. 3ê°œì›” ë™ì•ˆì˜ ì¬ê³  ë³€ë™ (ê·¸ë˜í”„)
        st.subheader("ğŸ“ˆ ìµœê·¼ 3ê°œì›” ì¬ê³  ë³€ë™ ê·¸ë˜í”„")
        
        fig = px.line(history_df, x='ì¼ì', y='ì¬ê³ ëŸ‰(ë°•ìŠ¤)', title=f'{p_name} ì¬ê³  ë³€ë™ ì¶”ì´ (90ì¼)', markers=True)
        fig.update_layout(
            xaxis_title='ì¼ì',
            yaxis_title='ì¬ê³ ëŸ‰(ë°•ìŠ¤)',
            yaxis_tickformat=','
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.error(f"**{p_name}**ì˜ ì¬ê³  ë‚´ì—­ì„ ì¡°íšŒí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
>>>>>>> 46ccaad40de1fda1a1b06e92242795ac69bdc0f3
