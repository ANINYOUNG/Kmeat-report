# pages/1_ì¬ê³ _ë¹„êµ_ë¶„ì„.py

import streamlit as st
import pandas as pd
import datetime
# import os # os.path.existsëŠ” ë” ì´ìƒ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
import traceback
import numpy as np

# common_utils.py ì—ì„œ ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë° ìƒìˆ˜ ê°€ì ¸ì˜¤ê¸°
from common_utils import (
    download_excel_from_drive_as_bytes, 
    get_all_available_sheet_dates_from_bytes,
    SM_QTY_COL_TREND as SM_QTY_COL, 
    SM_WGT_COL_TREND as SM_WGT_COL
)

# --- Google Drive íŒŒì¼ ID ì •ì˜ ---
# ì‚¬ìš©ìë‹˜ì´ ì œê³µí•´ì£¼ì‹  ì‹¤ì œ íŒŒì¼ IDë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
ERP_FILE_ID = "1Lbtwenw8LcDaj94_J4kKTjoWQY7PEAZs"
SM_FILE_ID = "1tRljdvOpp4fITaVEXvoL9mNveNg2qt4p"
# --- íŒŒì¼ ID ì •ì˜ ë ---


# --- ì´ í˜ì´ì§€ ê³ ìœ ì˜ ì„¤ì • ---
LOCATION_MAP = {
    "ëƒ‰ë™": "ì‹ ê°ˆëƒ‰ë™",
    "ìƒì´í’ˆ/ì‘ì—…": "ì‹ ê°ˆìƒì´í’ˆ/ì‘ì—…",
    "ì„ ì™•íŒë§¤": "ë°°ì •ë¶„"  # "ì¼€ì´ë¯¸íŠ¸ìŠ¤í† ì–´"ë¥¼ "ë°°ì •ë¶„"ìœ¼ë¡œ ìˆ˜ì •
}
ERP_TARGET_LOCATIONS = list(LOCATION_MAP.keys())
SM_TARGET_LOCATIONS = list(LOCATION_MAP.values())

SM_PROD_NAME_COL = 'ìƒí’ˆëª…' 
# SM_QTY_COL ì™€ SM_WGT_COL ì€ common_utilsì—ì„œ ê°€ì ¸ì˜¨ ê²ƒì„ ì‚¬ìš©


# --- Google Drive ì„œë¹„ìŠ¤ ê°ì²´ ê°€ì ¸ì˜¤ê¸° ---
retrieved_drive_service = st.session_state.get('drive_service')
page_title_for_debug = "ì¬ê³  ë¹„êµ ë¶„ì„ í˜ì´ì§€" 

if retrieved_drive_service:
    st.sidebar.info(f"'{page_title_for_debug}'ì—ì„œ Drive Service ë¡œë“œ ì„±ê³µ!")
else:
    st.sidebar.error(f"'{page_title_for_debug}'ì—ì„œ Drive Service ë¡œë“œ ì‹¤íŒ¨! (None). ë©”ì¸ í˜ì´ì§€ë¥¼ ë¨¼ì € ë°©ë¬¸í•˜ì—¬ ì¸ì¦ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")

drive_service = retrieved_drive_service


# --- ë¶„ì„ í•¨ìˆ˜ ì •ì˜ (Google Drive ì—°ë™ìœ¼ë¡œ ìˆ˜ì •) ---
@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None}) # drive_service í•´ì‹œ ë°©ì§€
def load_and_process_erp(_drive_service, file_id_erp, sheet_name): 
    erp_prod_name_col_raw = 'í’ˆëª©ëª…' 
    expected_cols = ['í˜¸ì‹¤', 'ìƒí’ˆì½”ë“œ', 'ìˆ˜ëŸ‰', 'ì¤‘ëŸ‰', erp_prod_name_col_raw]
    
    if _drive_service is None:
        st.error("ì˜¤ë¥˜: Google Drive ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ERP ë°ì´í„° ë¡œë”©)")
        return None

    file_bytes_erp = download_excel_from_drive_as_bytes(_drive_service, file_id_erp, f"ERP ì¬ê³ í˜„í™© ({sheet_name})")
    if file_bytes_erp is None:
        return None
        
    try:
        df_erp_raw = pd.read_excel(file_bytes_erp, sheet_name=sheet_name)
        # st.info(f"ERP ì›ë³¸ ({sheet_name}): {df_erp_raw.shape[0]} í–‰")

        if not all(col in df_erp_raw.columns for col in expected_cols):
            st.error(f"ì˜¤ë¥˜: ERP ì‹œíŠ¸({sheet_name}) í•„ìš” ì»¬ëŸ¼({expected_cols}) ì—†ìŒ. ì»¬ëŸ¼: {df_erp_raw.columns.tolist()}")
            return None

        df_erp = df_erp_raw[df_erp_raw['í˜¸ì‹¤'].isin(ERP_TARGET_LOCATIONS)].copy()
        if df_erp.empty: 
            st.warning(f"ERP ëŒ€ìƒ í˜¸ì‹¤({ERP_TARGET_LOCATIONS}) ë°ì´í„° ì—†ìŒ ({sheet_name})")
            return pd.DataFrame()

        df_erp = df_erp[['í˜¸ì‹¤', 'ìƒí’ˆì½”ë“œ', erp_prod_name_col_raw, 'ìˆ˜ëŸ‰', 'ì¤‘ëŸ‰']].copy()
        df_erp['ì§€ì ëª…'] = df_erp['í˜¸ì‹¤'].map(LOCATION_MAP)
        df_erp.drop(columns=['í˜¸ì‹¤'], inplace=True)
        df_erp['ìƒí’ˆì½”ë“œ'] = df_erp['ìƒí’ˆì½”ë“œ'].astype(str).str.strip()
        df_erp[erp_prod_name_col_raw] = df_erp[erp_prod_name_col_raw].astype(str).str.strip()
        df_erp['ìˆ˜ëŸ‰'] = pd.to_numeric(df_erp['ìˆ˜ëŸ‰'], errors='coerce').fillna(0)
        df_erp['ì¤‘ëŸ‰'] = pd.to_numeric(df_erp['ì¤‘ëŸ‰'], errors='coerce').fillna(0)

        if not df_erp.empty:
            df_erp = df_erp.groupby(['ì§€ì ëª…', 'ìƒí’ˆì½”ë“œ'], as_index=False).agg(
                ìƒí’ˆëª…_ERP=(erp_prod_name_col_raw, 'first'),
                ìˆ˜ëŸ‰=('ìˆ˜ëŸ‰', 'sum'),
                ì¤‘ëŸ‰=('ì¤‘ëŸ‰', 'sum')
            )
        
        original_erp_count = len(df_erp)
        if not df_erp.empty: df_erp = df_erp[~((df_erp['ìˆ˜ëŸ‰'] == 0) & (df_erp['ì¤‘ëŸ‰'] == 0))]
        
        df_erp['key'] = df_erp['ìƒí’ˆì½”ë“œ'] + '-' + df_erp['ì§€ì ëª…']
        return df_erp
    except ValueError as ve:
        if f"Worksheet named '{sheet_name}' not found" in str(ve): 
            st.error(f"ì˜¤ë¥˜: ERP íŒŒì¼ (ID: {file_id_erp})ì— '{sheet_name}' ì‹œíŠ¸ ì—†ìŒ")
        else: 
            st.error(f"ERP ë°ì´í„° (ID: {file_id_erp}, ì‹œíŠ¸: {sheet_name}) ë¡œë“œ/ì²˜ë¦¬ ì¤‘ ê°’ ì˜¤ë¥˜: {ve}")
        return None
    except Exception as e: 
        st.error(f"ERP ë°ì´í„° (ID: {file_id_erp}, ì‹œíŠ¸: {sheet_name}) ë¡œë“œ/ì²˜ë¦¬ ì¤‘ ì˜ˆìƒ ëª»í•œ ì˜¤ë¥˜: {e}")
        return None

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None}) # drive_service í•´ì‹œ ë°©ì§€
def load_and_process_sm(_drive_service, file_id_sm, sheet_name): 
    if _drive_service is None:
        st.error("ì˜¤ë¥˜: Google Drive ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (SM ë°ì´í„° ë¡œë”©)")
        return None

    file_bytes_sm = download_excel_from_drive_as_bytes(_drive_service, file_id_sm, f"SM ì¬ê³ í˜„í™© ({sheet_name})")
    if file_bytes_sm is None:
        return None

    try:
        required_sm_cols = ['ì§€ì ëª…', 'ìƒí’ˆì½”ë“œ', SM_PROD_NAME_COL, SM_QTY_COL, SM_WGT_COL]
        df_sm_raw = pd.read_excel(file_bytes_sm, sheet_name=sheet_name)
        # st.info(f"SM ì›ë³¸ ({sheet_name}): {df_sm_raw.shape[0]} í–‰")

        if not all(col in df_sm_raw.columns for col in required_sm_cols):
            missing_cols = [col for col in required_sm_cols if col not in df_sm_raw.columns]
            st.error(f"ì˜¤ë¥˜: SM ì‹œíŠ¸({sheet_name}) í•„ìš” ì»¬ëŸ¼({missing_cols}) ì—†ìŒ. ì»¬ëŸ¼: {df_sm_raw.columns.tolist()}")
            return None

        df_sm = df_sm_raw[df_sm_raw['ì§€ì ëª…'].isin(SM_TARGET_LOCATIONS)].copy()
        if df_sm.empty: 
            st.warning(f"SM ëŒ€ìƒ ì§€ì ëª…({SM_TARGET_LOCATIONS}) ë°ì´í„° ì—†ìŒ ({sheet_name})")
            return pd.DataFrame()

        df_sm = df_sm[required_sm_cols].copy()
        df_sm['ìƒí’ˆì½”ë“œ'] = df_sm['ìƒí’ˆì½”ë“œ'].astype(str).str.strip()
        df_sm['ì§€ì ëª…'] = df_sm['ì§€ì ëª…'].astype(str).str.strip()
        df_sm[SM_PROD_NAME_COL] = df_sm[SM_PROD_NAME_COL].astype(str).str.strip()
        df_sm[SM_QTY_COL] = pd.to_numeric(df_sm[SM_QTY_COL], errors='coerce').fillna(0)
        df_sm[SM_WGT_COL] = pd.to_numeric(df_sm[SM_WGT_COL], errors='coerce').fillna(0)

        if not df_sm.empty:
            df_sm = df_sm.groupby(['ì§€ì ëª…', 'ìƒí’ˆì½”ë“œ'], as_index=False).agg(
                ìƒí’ˆëª…_SM=(SM_PROD_NAME_COL, 'first'),
                QtySum=(SM_QTY_COL, 'sum'),
                WgtSum=(SM_WGT_COL, 'sum')
            ).rename(columns={'QtySum': SM_QTY_COL, 'WgtSum': SM_WGT_COL})

        original_sm_count = len(df_sm)
        if not df_sm.empty: df_sm = df_sm[~((df_sm[SM_QTY_COL] == 0) & (df_sm[SM_WGT_COL] == 0))]
        
        df_sm['key'] = df_sm['ìƒí’ˆì½”ë“œ'] + '-' + df_sm['ì§€ì ëª…']
        return df_sm
    except ValueError as ve:
        if f"Worksheet named '{sheet_name}' not found" in str(ve): 
            st.error(f"ì˜¤ë¥˜: SM íŒŒì¼ (ID: {file_id_sm})ì— '{sheet_name}' ì‹œíŠ¸ ì—†ìŒ")
        else: 
            st.error(f"SM ë°ì´í„° (ID: {file_id_sm}, ì‹œíŠ¸: {sheet_name}) ë¡œë“œ/ì²˜ë¦¬ ì¤‘ ê°’ ì˜¤ë¥˜: {ve}")
        return None
    except Exception as e: 
        st.error(f"SM ë°ì´í„° (ID: {file_id_sm}, ì‹œíŠ¸: {sheet_name}) ë¡œë“œ/ì²˜ë¦¬ ì¤‘ ì˜ˆìƒ ëª»í•œ ì˜¤ë¥˜: {e}")
        return None

def compare_inventories(df_erp, df_sm):
    if df_erp is None or df_sm is None or df_erp.empty or df_sm.empty : 
        st.warning("ERP ë˜ëŠ” SM ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ë¹„êµ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        erp_len = len(df_erp) if df_erp is not None and not df_erp.empty else 0
        sm_len = len(df_sm) if df_sm is not None and not df_sm.empty else 0
        
        summary = {'erp_total': erp_len, 'sm_total': sm_len, 'common_total': 0, 
                   'only_erp_count': erp_len, 'only_sm_count': sm_len,
                   'match_count': 0, 'mismatch_count': 0, 'match_rate': 0.0}
        
        only_erp_cols = ['ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…_ERP', 'ì§€ì ëª…', 'ìˆ˜ëŸ‰', 'ì¤‘ëŸ‰'] 
        only_sm_cols = ['ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…_SM', 'ì§€ì ëª…', SM_QTY_COL, SM_WGT_COL] 
        mismatch_cols = ['ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…', 'ì§€ì ëª…', 'ìˆ˜ëŸ‰', SM_QTY_COL, 'ìˆ˜ëŸ‰ì°¨ì´', 'ì¤‘ëŸ‰', SM_WGT_COL, 'ì¤‘ëŸ‰ì°¨ì´']

        df_only_erp = pd.DataFrame(columns=only_erp_cols)
        df_only_sm = pd.DataFrame(columns=only_sm_cols)

        if df_erp is not None and not df_erp.empty:
            erp_display_cols = [col for col in only_erp_cols if col in df_erp.columns]
            df_only_erp = df_erp[erp_display_cols].copy()

        if df_sm is not None and not df_sm.empty:
            sm_display_cols = [col for col in only_sm_cols if col in df_sm.columns]
            df_only_sm = df_sm[sm_display_cols].copy()
            
        return summary, df_only_erp, df_only_sm, pd.DataFrame(columns=mismatch_cols)

    df_merged = pd.merge(
        df_erp[['key', 'ìƒí’ˆì½”ë“œ', 'ì§€ì ëª…', 'ìƒí’ˆëª…_ERP', 'ìˆ˜ëŸ‰', 'ì¤‘ëŸ‰']],
        df_sm[['key', 'ìƒí’ˆëª…_SM', SM_QTY_COL, SM_WGT_COL]], 
        on='key', how='outer', indicator=True
    )

    num_cols = ['ìˆ˜ëŸ‰', 'ì¤‘ëŸ‰', SM_QTY_COL, SM_WGT_COL]
    for col in num_cols:
        if col in df_merged.columns: df_merged[col] = pd.to_numeric(df_merged[col].fillna(0), errors='coerce').fillna(0)
    
    df_merged['ìƒí’ˆëª…_ERP'] = df_merged['ìƒí’ˆëª…_ERP'].fillna('')
    df_merged['ìƒí’ˆëª…_SM'] = df_merged['ìƒí’ˆëª…_SM'].fillna('')
    df_merged['ìƒí’ˆëª…'] = df_merged.apply(lambda row: row['ìƒí’ˆëª…_ERP'] if row['ìƒí’ˆëª…_ERP'] else row['ìƒí’ˆëª…_SM'], axis=1)

    only_erp = df_merged[df_merged['_merge'] == 'left_only'].copy()
    only_sm = df_merged[df_merged['_merge'] == 'right_only'].copy()
    both = df_merged[df_merged['_merge'] == 'both'].copy()
    
    if not only_erp.empty: only_erp['ìƒí’ˆëª…'] = only_erp['ìƒí’ˆëª…_ERP'] 
    if not only_sm.empty: 
        only_sm['ìƒí’ˆëª…'] = only_sm['ìƒí’ˆëª…_SM'] 
        try:
            split_key = only_sm['key'].str.split('-', n=1, expand=True)
            if split_key.shape[1] > 0: only_sm['ìƒí’ˆì½”ë“œ'] = split_key[0]
            if split_key.shape[1] > 1: only_sm['ì§€ì ëª…'] = split_key[1]
        except Exception as e_split:
            st.warning(f"SM ì „ìš© ë°ì´í„° Key ë¶„ë¦¬ ì¤‘ ì˜¤ë¥˜: {e_split}.")
            if 'ìƒí’ˆì½”ë“œ' not in only_sm.columns: only_sm['ìƒí’ˆì½”ë“œ'] = 'ë¶„ë¦¬ ì˜¤ë¥˜'
            if 'ì§€ì ëª…' not in only_sm.columns: only_sm['ì§€ì ëª…'] = 'ë¶„ë¦¬ ì˜¤ë¥˜'

    summary = {
        'erp_total': len(df_erp), 'sm_total': len(df_sm), 'common_total': len(both),
        'only_erp_count': len(only_erp), 'only_sm_count': len(only_sm),
        'match_count': 0, 'mismatch_count': 0, 'match_rate': 0.0
    }
    mismatches_list = pd.DataFrame()

    if not both.empty:
        both['ìˆ˜ëŸ‰ì°¨ì´'] = both['ìˆ˜ëŸ‰'] - both[SM_QTY_COL]
        both['ì¤‘ëŸ‰ì°¨ì´'] = both['ì¤‘ëŸ‰'] - both[SM_WGT_COL]
        tolerance = 1e-9
        qty_match = np.isclose(both['ìˆ˜ëŸ‰ì°¨ì´'], 0, atol=tolerance)
        erp_wgt_rounded = both['ì¤‘ëŸ‰'].round(2) 
        sm_wgt_rounded = both[SM_WGT_COL].round(2) 
        wgt_match = np.isclose(erp_wgt_rounded, sm_wgt_rounded, atol=tolerance)
        full_match = qty_match & wgt_match
        summary['match_count'] = int(full_match.sum())
        summary['mismatch_count'] = len(both) - summary['match_count']
        summary['match_rate'] = (summary['match_count'] / len(both)) * 100 if len(both) > 0 else 0.0
        
        mismatch_cols_def = ['ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…', 'ì§€ì ëª…', 'ìˆ˜ëŸ‰', SM_QTY_COL, 'ìˆ˜ëŸ‰ì°¨ì´', 'ì¤‘ëŸ‰', SM_WGT_COL, 'ì¤‘ëŸ‰ì°¨ì´']
        mismatches_list = both.loc[~full_match, [col for col in mismatch_cols_def if col in both.columns]].copy()

    only_erp_cols_def = ['ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…', 'ì§€ì ëª…', 'ìˆ˜ëŸ‰', 'ì¤‘ëŸ‰']
    only_erp_return = only_erp[[col for col in only_erp_cols_def if col in only_erp.columns]].copy() if not only_erp.empty else pd.DataFrame(columns=only_erp_cols_def)
    
    only_sm_cols_def = ['ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…', 'ì§€ì ëª…', SM_QTY_COL, SM_WGT_COL]
    only_sm_return = only_sm[[col for col in only_sm_cols_def if col in only_sm.columns]].copy() if not only_sm.empty else pd.DataFrame(columns=only_sm_cols_def)

    if mismatches_list.empty: mismatches_list = pd.DataFrame(columns=mismatch_cols_def)

    return summary, only_erp_return, only_sm_return, mismatches_list

# --- Streamlit í˜ì´ì§€ UI êµ¬ì„± ---
st.title("ğŸ”„ ERP vs SM ì¬ê³  ë¹„êµ ë¶„ì„")
st.markdown("---")

if drive_service is None: 
    st.error("Google Drive ì„œë¹„ìŠ¤ì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•±ì˜ ë©”ì¸ í˜ì´ì§€ë¥¼ ë°©ë¬¸í•˜ì—¬ ì¸ì¦ì„ ì™„ë£Œí•˜ê±°ë‚˜, ì•± ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

st.markdown(f"ëŒ€ìƒ ERP í˜¸ì‹¤: `{', '.join(ERP_TARGET_LOCATIONS)}` â†” ëŒ€ìƒ SM ì§€ì ëª…: `{', '.join(SM_TARGET_LOCATIONS)}`")
st.markdown(f"SM ì¬ê³  ë¹„êµ ê¸°ì¤€ ì»¬ëŸ¼: ìˆ˜ëŸ‰=`{SM_QTY_COL}`, ì¤‘ëŸ‰=`{SM_WGT_COL}`")
st.markdown("---")

available_sm_dates = []
# SM_FILE_IDê°€ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì•„ë‹Œ ì‹¤ì œ IDì¸ì§€ í™•ì¸
if SM_FILE_ID and not SM_FILE_ID.startswith("YOUR_"): 
    sm_file_bytes = download_excel_from_drive_as_bytes(drive_service, SM_FILE_ID, "SMì¬ê³ í˜„í™© (ë‚ ì§œì¡°íšŒìš©)")
    if sm_file_bytes:
        available_sm_dates = get_all_available_sheet_dates_from_bytes(sm_file_bytes, "SMì¬ê³ í˜„í™© (ë‚ ì§œì¡°íšŒìš©)")
else:
    st.warning("SM_FILE_IDê°€ ì½”ë“œì— ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì½”ë“œ ìƒë‹¨ì—ì„œ ì‹¤ì œ íŒŒì¼ IDë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")


default_date_to_show = datetime.date.today()
min_date_for_picker = None
max_date_for_picker = None

if available_sm_dates:
    available_sm_dates_asc = sorted(available_sm_dates, reverse=False)
    min_date_for_picker = available_sm_dates_asc[0]
    max_date_for_picker = available_sm_dates_asc[-1] 
    default_date_to_show = max_date_for_picker 
    
    st.info(f"SM íŒŒì¼ ê¸°ì¤€ ë°ì´í„° ë³´ìœ  ë‚ ì§œ ë²”ìœ„: {min_date_for_picker.strftime('%Y-%m-%d')} ~ {max_date_for_picker.strftime('%Y-%m-%d')}")
    if st.checkbox("SM íŒŒì¼ ë°ì´í„° ë³´ìœ  ëª¨ë“  ë‚ ì§œ ë³´ê¸° (ìµœì‹  100ê°œ)", False, key="cb_show_sm_dates_comparison"):
        display_limit = 100
        dates_to_show_str = [d.strftime('%Y-%m-%d') for d in sorted(available_sm_dates, reverse=True)[:display_limit]]
        st.markdown(f"<small>í‘œì‹œëœ ë‚ ì§œ ìˆ˜: {len(dates_to_show_str)}. ì „ì²´ SM ë°ì´í„° ë³´ìœ  ì¼ìˆ˜: {len(available_sm_dates)}</small>", unsafe_allow_html=True)
        st.text_area("SM ë°ì´í„° ë³´ìœ  ë‚ ì§œ:", ", ".join(dates_to_show_str), height=100, key="sm_dates_list_area")
    st.markdown("<small>ìœ„ ëª©ë¡ì€ SMíŒŒì¼ ê¸°ì¤€ì´ë©°, ERPíŒŒì¼ì—ë„ í•´ë‹¹ ë‚ ì§œì˜ ì‹œíŠ¸ê°€ ìˆì–´ì•¼ ë¹„êµ ê°€ëŠ¥í•©ë‹ˆë‹¤.</small>", unsafe_allow_html=True)
else:
    # SM_FILE_IDê°€ ì„¤ì •ë˜ì—ˆì§€ë§Œ ë‚ ì§œ ì •ë³´ë¥¼ ëª» ê°€ì ¸ì˜¨ ê²½ìš°ì— ëŒ€í•œ ê²½ê³ 
    if SM_FILE_ID and not SM_FILE_ID.startswith("YOUR_"): 
        st.warning(f"'SMì¬ê³ í˜„í™©.xlsx' (ID: {SM_FILE_ID})ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë‚ ì§œ ì„ íƒ ë²”ìœ„ë¥¼ ì œí•œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ë‚ ì§œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

selected_date_obj = st.date_input(
    "ë¶„ì„ ê¸°ì¤€ ë‚ ì§œ ì„ íƒ", 
    default_date_to_show,
    min_value=min_date_for_picker,
    max_value=max_date_for_picker
)

if selected_date_obj:
    target_sheet_name = selected_date_obj.strftime("%Y%m%d")
    st.info(f"**ì„ íƒëœ ë‚ ì§œ:** {selected_date_obj.strftime('%Y-%m-%d')} (ëŒ€ìƒ ì‹œíŠ¸: {target_sheet_name})")

    if st.button("ì¬ê³  ë¹„êµ ë¶„ì„ ì‹¤í–‰", key="btn_run_comparison"):
        # ERP_FILE_IDì™€ SM_FILE_IDê°€ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ì•„ë‹Œì§€ ë‹¤ì‹œ í•œë²ˆ í™•ì¸
        if (ERP_FILE_ID and ERP_FILE_ID.startswith("YOUR_")) or \
           (SM_FILE_ID and SM_FILE_ID.startswith("YOUR_")):
            st.error("ERP ë˜ëŠ” SM íŒŒì¼ IDê°€ ì½”ë“œì— ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì½”ë“œ ìƒë‹¨ì˜ íŒŒì¼ IDë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ë¶„ì„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                df_erp = load_and_process_erp(drive_service, ERP_FILE_ID, target_sheet_name)
                df_sm = load_and_process_sm(drive_service, SM_FILE_ID, target_sheet_name)

                summary, df_only_erp, df_only_sm, df_mismatches = compare_inventories(df_erp, df_sm)
                
                st.markdown("---")
                st.header("ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
                
                col1, col2, col3 = st.columns(3); col4, col5, col6 = st.columns(3); col7, col8 = st.columns(2)
                col1.metric("ERP ëŒ€ìƒ í•­ëª©", summary['erp_total'])
                col2.metric("SM ëŒ€ìƒ í•­ëª©", summary['sm_total'])
                col3.metric("ê³µí†µ í•­ëª©", summary['common_total'])
                col4.metric("ERP ì—ë§Œ ì¡´ì¬", summary['only_erp_count'], delta=f"{summary['only_erp_count']}" if summary['only_erp_count'] else None, delta_color="off")
                col5.metric("SM ì—ë§Œ ì¡´ì¬", summary['only_sm_count'], delta=f"{summary['only_sm_count']}" if summary['only_sm_count'] else None, delta_color="off")
                col6.metric("ì™„ì „ ì¼ì¹˜ í•­ëª©", summary['match_count'])
                col7.metric("ë¶ˆì¼ì¹˜ í•­ëª©", summary['mismatch_count'], delta=f"{summary['mismatch_count']}" if summary['mismatch_count'] else None, delta_color="off")
                match_rate_display = f"{summary['match_rate']:.2f} %" if summary['common_total'] > 0 else "N/A"
                col8.metric("ğŸŸ¢ ì¬ê³  ì™„ì „ ì¼ì¹˜ìœ¨ (ê³µí†µ í•­ëª© ì¤‘)", match_rate_display)
                st.markdown("---")

                st.header("ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
                if df_only_erp is not None and not df_only_erp.empty: 
                    with st.expander(f"ERP ì—ë§Œ ìˆëŠ” í•­ëª© ({summary['only_erp_count']} ê±´)", expanded=False):
                        df_only_erp_display = df_only_erp.rename(columns={'ìƒí’ˆëª…_ERP': 'ìƒí’ˆëª…'})
                        st.dataframe(df_only_erp_display[['ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…', 'ì§€ì ëª…', 'ìˆ˜ëŸ‰', 'ì¤‘ëŸ‰']], use_container_width=True)
                
                if df_only_sm is not None and not df_only_sm.empty: 
                    with st.expander(f"SM ì—ë§Œ ìˆëŠ” í•­ëª© ({summary['only_sm_count']} ê±´)", expanded=False):
                        df_only_sm_display = df_only_sm.rename(columns={
                            'ìƒí’ˆëª…_SM': 'ìƒí’ˆëª…', 
                            SM_QTY_COL: f'ìˆ˜ëŸ‰({SM_QTY_COL.replace("ì”ëŸ‰(","").replace(")","")})', 
                            SM_WGT_COL: f'ì¤‘ëŸ‰({SM_WGT_COL.replace("ì”ëŸ‰(","").replace(")","")})'
                        })
                        display_cols_sm = ['ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…', 'ì§€ì ëª…', 
                                           f'ìˆ˜ëŸ‰({SM_QTY_COL.replace("ì”ëŸ‰(","").replace(")","")})', 
                                           f'ì¤‘ëŸ‰({SM_WGT_COL.replace("ì”ëŸ‰(","").replace(")","")})']
                        st.dataframe(df_only_sm_display[[col for col in display_cols_sm if col in df_only_sm_display.columns]], use_container_width=True)

                if df_mismatches is not None and not df_mismatches.empty: 
                    with st.expander(f"ìˆ˜ëŸ‰/ì¤‘ëŸ‰ ë¶ˆì¼ì¹˜ í•­ëª© ({summary['mismatch_count']} ê±´)", expanded=True):
                        df_mismatches_display = df_mismatches.rename(columns={
                            'ìˆ˜ëŸ‰': 'ìˆ˜ëŸ‰(ERP)', SM_QTY_COL: f'ìˆ˜ëŸ‰(SM)', 
                            'ì¤‘ëŸ‰': 'ì¤‘ëŸ‰(ERP)', SM_WGT_COL: f'ì¤‘ëŸ‰(SM)'
                        })
                        display_cols_mismatch = ['ìƒí’ˆì½”ë“œ', 'ìƒí’ˆëª…', 'ì§€ì ëª…', 'ìˆ˜ëŸ‰(ERP)', f'ìˆ˜ëŸ‰(SM)', 'ìˆ˜ëŸ‰ì°¨ì´', 'ì¤‘ëŸ‰(ERP)', f'ì¤‘ëŸ‰(SM)', 'ì¤‘ëŸ‰ì°¨ì´']
                        try:
                            for col_diff in ['ìˆ˜ëŸ‰ì°¨ì´', 'ì¤‘ëŸ‰ì°¨ì´']:
                                if col_diff in df_mismatches_display:
                                    df_mismatches_display[col_diff] = pd.to_numeric(df_mismatches_display[col_diff], errors='coerce').map('{:,.2f}'.format)
                        except Exception as e_format:
                            st.caption(f"ì°¨ì´ê°’ í¬ë§·íŒ… ì¤‘ ì‘ì€ ì˜¤ë¥˜ ë°œìƒ: {e_format}")
                        st.dataframe(df_mismatches_display[[col for col in display_cols_mismatch if col in df_mismatches_display.columns]], use_container_width=True)
else:
    st.info("ë¶„ì„í•  ë‚ ì§œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")