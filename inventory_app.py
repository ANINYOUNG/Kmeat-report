# inventory_app.py (ë©”ì¸ í˜ì´ì§€ íŒŒì¼)

import streamlit as st
import pandas as pd
import datetime
from dateutil.relativedelta import relativedelta
import os
import traceback
import plotly.express as px
import json
import io

# --- 3. Google Drive API ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaIoBaseDownload

# --- 4. ì™¸ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸ ---
# memo_manager.py íŒŒì¼ì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from memo_manager import ensure_memos_loaded, initialize_memo_sidebar, render_sticky_notes

# --- í˜ì´ì§€ ì„¤ì • (ê°€ì¥ ë¨¼ì € í˜¸ì¶œ) ---
st.set_page_config(page_title="ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide", initial_sidebar_state="expanded")


# --- ìƒìˆ˜ ì •ì˜ ---
KOREAN_DAYS = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
DRIVE_SCOPES = ['https://www.googleapis.com/auth/drive']
SM_FILE_ID = "1tRljdvOpp4fITaVEXvoL9mNveNg2qt4p"
PURCHASE_FILE_ID = "1AgKl29yQ80sTDszLql6oBnd9FnLWf8oR"
SALES_FILE_ID = "1h-V7kIoInXgGLll7YBW5V_uZdF3Q1PdY"
MEMO_FILE_ID = "1ZQk9SqudpujLmoP7SXW89DXBZyXpLuQI" 
SM_QTY_COL_TREND = 'ì”ëŸ‰(ë°•ìŠ¤)'
SM_WGT_COL_TREND = 'ì”ëŸ‰(Kg)'
REPORT_LOCATION_MAP_TREND = {'ì‹ ê°ˆëƒ‰ë™': 'ì‹ ê°ˆ', 'ì„ ì™•CH4ì¸µ': 'ì„ ì™•', 'ì‹ ê°ˆê¹€í˜•ì œ': 'ê¹€í˜•ì œ', 'ì‹ ê°ˆìƒì´í’ˆ/ì‘ì—…': 'ìƒì´í’ˆ', 'ì¼€ì´ë¯¸íŠ¸ìŠ¤í† ì–´': 'ìŠ¤í† ì–´'}
TARGET_SM_LOCATIONS_FOR_TREND = ['ì‹ ê°ˆëƒ‰ë™', 'ì„ ì™•CH4ì¸µ', 'ì‹ ê°ˆê¹€í˜•ì œ', 'ì‹ ê°ˆìƒì´í’ˆ/ì‘ì—…', 'ì¼€ì´ë¯¸íŠ¸ìŠ¤í† ì–´']
REPORT_ROW_ORDER_TREND = ['ì‹ ê°ˆ', 'ì„ ì™•', 'ê¹€í˜•ì œ', 'ìƒì´í’ˆ', 'ìŠ¤í† ì–´']
PURCHASE_DATE_COL = 'ë§¤ì…ì¼ì'; PURCHASE_CODE_COL = 'ì½”ë“œ'; PURCHASE_CUSTOMER_COL = 'ê±°ë˜ì²˜ëª…'
PURCHASE_PROD_CODE_COL = 'ìƒí’ˆì½”ë“œ'; PURCHASE_PROD_NAME_COL = 'ìƒ í’ˆ ëª…'; PURCHASE_LOCATION_COL = 'ì§€ ì  ëª…'
PURCHASE_QTY_BOX_COL = 'Box'; PURCHASE_QTY_KG_COL = 'Kg'
PURCHASE_LOG_SHEET_NAME = 'p-list'
SALES_DATE_COL = 'ë§¤ì¶œì¼ì'; SALES_PROD_CODE_COL = 'ìƒí’ˆì½”ë“œ'; SALES_PROD_NAME_COL = 'ìƒ  í’ˆ  ëª…'
SALES_QTY_BOX_COL = 'ìˆ˜ëŸ‰(Box)'; SALES_QTY_KG_COL = 'ìˆ˜ëŸ‰(Kg)'; SALES_LOCATION_COL = 'ì§€ì ëª…'
SALES_LOG_SHEET_NAME = 's-list'
SUMMARY_TABLE_LOCATIONS = ['ì‹ ê°ˆëƒ‰ë™', 'ì„ ì™•CH4ì¸µ', 'ì‹ ê°ˆê¹€í˜•ì œ', 'ì‹ ê°ˆìƒì´í’ˆ/ì‘ì—…', 'ì¼€ì´ë¯¸íŠ¸ìŠ¤í† ì–´']


# --- ì¸ì¦ ë° ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ---
@st.cache_resource
def get_drive_service():
    """Google Drive ì„œë¹„ìŠ¤ ê°ì²´ë¥¼ ìƒì„±í•˜ê³  ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    if "google_creds_json" in st.secrets:
        try:
            creds_dict = json.loads(st.secrets["google_creds_json"])
            creds = Credentials.from_service_account_info(creds_dict, scopes=DRIVE_SCOPES)
            return build('drive', 'v3', credentials=creds)
        except Exception as e:
            st.sidebar.error(f"í´ë¼ìš°ë“œ Secrets ì¸ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    else:
        SERVICE_ACCOUNT_FILE_PATH = "your_service_account.json" 
        if os.path.exists(SERVICE_ACCOUNT_FILE_PATH):
            try:
                creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE_PATH, scopes=DRIVE_SCOPES)
                return build('drive', 'v3', credentials=creds)
            except Exception as e:
                st.sidebar.error(f"ë¡œì»¬ í‚¤ íŒŒì¼ ì¸ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
                return None
        return None

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def download_excel_from_drive_as_bytes(_drive_service, file_id, file_name_for_error_msg="Excel file"):
    if _drive_service is None: return None
    try:
        request = _drive_service.files().get_media(fileId=file_id)
        fh = io.BytesIO(); downloader = MediaIoBaseDownload(fh, request); done = False
        while not done: status, done = downloader.next_chunk()
        fh.seek(0); return fh
    except Exception: return None

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def get_all_available_sheet_dates_from_excel_drive(_drive_service, file_id, file_name_for_error_msg="SMì¬ê³ í˜„í™©.xlsx"):
    fh = download_excel_from_drive_as_bytes(_drive_service, file_id, file_name_for_error_msg)
    if fh is None: return []
    try:
        xls = pd.ExcelFile(fh); sheet_names = xls.sheet_names; valid_dates = []
        for name in sheet_names:
            try: dt_obj = datetime.datetime.strptime(name, "%Y%m%d").date(); valid_dates.append(dt_obj)
            except ValueError: continue
        valid_dates.sort(reverse=True); return valid_dates
    except Exception: return []

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def load_sm_data_from_excel_drive(_drive_service, file_id, date_strings_yyyymmdd_list, file_name_for_error_msg="SMì¬ê³ í˜„í™©.xlsx"):
    if not date_strings_yyyymmdd_list: return None
    fh = download_excel_from_drive_as_bytes(_drive_service, file_id, file_name_for_error_msg)
    if fh is None: return None
    all_data = []
    try:
        xls = pd.ExcelFile(fh)
        available_sheets = xls.sheet_names
        for date_str in date_strings_yyyymmdd_list:
            if date_str in available_sheets:
                try:
                    df_sheet = pd.read_excel(xls, sheet_name=date_str, header=0)
                    df_sheet.dropna(how='all', inplace=True)
                    if df_sheet.empty: continue
                    required_cols = ['ì§€ì ëª…', 'ìƒí’ˆì½”ë“œ', SM_QTY_COL_TREND, SM_WGT_COL_TREND]
                    if not all(col in df_sheet.columns for col in required_cols):
                        missing = [col for col in required_cols if col not in df_sheet.columns]
                        st.warning(f"ê²½ê³ : '{file_name_for_error_msg}' (ID: {file_id}) íŒŒì¼ì˜ '{date_str}' ì‹œíŠ¸ì— í•„ìˆ˜ ì»¬ëŸ¼ {missing} ì¤‘ ì¼ë¶€ê°€ ëˆ„ë½ë˜ì–´ í•´ë‹¹ ì‹œíŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                        continue
                    df_sheet_copy = df_sheet.copy()
                    df_sheet_copy['ë‚ ì§œ'] = pd.to_datetime(date_str, format='%Y%m%d')
                    df_processed_sheet = df_sheet_copy[['ë‚ ì§œ', 'ì§€ì ëª…', 'ìƒí’ˆì½”ë“œ', SM_QTY_COL_TREND, SM_WGT_COL_TREND]].copy()
                    for col in [SM_QTY_COL_TREND, SM_WGT_COL_TREND]:
                        df_processed_sheet[col] = pd.to_numeric(df_processed_sheet[col], errors='coerce').fillna(0)
                    df_processed_sheet['ì§€ì ëª…'] = df_processed_sheet['ì§€ì ëª…'].astype(str).str.strip()
                    df_processed_sheet['ë‚ ì§œ'] = pd.to_datetime(df_processed_sheet['ë‚ ì§œ']).dt.normalize()
                    all_data.append(df_processed_sheet)
                except Exception as e_sheet:
                    st.warning(f"ê²½ê³ : '{file_name_for_error_msg}' (ID: {file_id}) íŒŒì¼ì˜ ì‹œíŠ¸ '{date_str}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e_sheet}")
                    continue
        if not all_data: return None
        return pd.concat(all_data, ignore_index=True)
    except Exception as e_main:
        st.error(f"ì˜¤ë¥˜: '{file_name_for_error_msg}' (ID: {file_id}) ì—‘ì…€ íŒŒì¼ ë¡œë”© ì¤‘ ì£¼ìš” ì˜¤ë¥˜ ë°œìƒ: {e_main}")
        return None

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def get_latest_date_from_log_drive(_drive_service, file_id, sheet_name, date_col, file_name_for_error_msg=""):
    fh = download_excel_from_drive_as_bytes(_drive_service, file_id, file_name_for_error_msg)
    if fh is None: return None
    try:
        df = pd.read_excel(fh, sheet_name=sheet_name, header=0)
        df.dropna(subset=[date_col], how='all', inplace=True)
        if df.empty or date_col not in df.columns: return None
        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
        df.dropna(subset=[date_col], inplace=True)
        if df.empty: return None
        return df[date_col].max().date()
    except Exception as e:
        st.warning(f"ê²½ê³ : '{file_name_for_error_msg}' (ID: {file_id}, ì‹œíŠ¸: {sheet_name}) ìµœì‹  ë‚ ì§œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def load_daily_log_data_for_period_from_excel_drive(_drive_service, file_id, sheet_name, date_col, location_col, qty_box_col, qty_kg_col, start_date, end_date, is_purchase_log=False, file_name_for_error_msg=""):
    fh = download_excel_from_drive_as_bytes(_drive_service, file_id, file_name_for_error_msg)
    if fh is None: return pd.DataFrame()
    try:
        df = pd.read_excel(fh, sheet_name=sheet_name, header=0)
        df.dropna(how='all', inplace=True)
        if df.empty: return pd.DataFrame()
        if is_purchase_log:
            ffill_cols = [date_col, location_col, PURCHASE_CODE_COL, PURCHASE_CUSTOMER_COL]
            for col_to_ffill in ffill_cols:
                if col_to_ffill in df.columns:
                    df[col_to_ffill] = df[col_to_ffill].ffill()
                elif col_to_ffill == date_col or col_to_ffill == location_col:
                    return pd.DataFrame()
        required_cols_log = [date_col, location_col, qty_box_col, qty_kg_col]
        if not all(col in df.columns for col in required_cols_log):
            return pd.DataFrame()
        df[date_col] = pd.to_datetime(df[date_col], errors='coerce').dt.normalize()
        df.dropna(subset=[date_col], inplace=True)
        if df.empty: return pd.DataFrame()
        mask = (df[date_col].dt.date >= start_date) & (df[date_col].dt.date <= end_date)
        df_period = df.loc[mask].copy()
        if df_period.empty: return pd.DataFrame()
        for col in [qty_box_col, qty_kg_col]:
            df_period[col] = pd.to_numeric(df_period[col], errors='coerce').fillna(0)
        df_period[location_col] = df_period[location_col].astype(str).str.strip()
        daily_summary = df_period.groupby([df_period[date_col].dt.date, location_col]).agg(
            TotalQtyBox=(qty_box_col, 'sum'),
            TotalQtyKg=(qty_kg_col, 'sum')
        ).reset_index()
        daily_summary.rename(columns={date_col: 'ë‚ ì§œ'}, inplace=True)
        return daily_summary
    except Exception:
        return pd.DataFrame()

@st.cache_data(ttl=300, hash_funcs={"googleapiclient.discovery.Resource": lambda _: None})
def load_log_data_for_period_from_excel_drive(_drive_service, file_id, sheet_name, date_col, qty_kg_col, location_col, start_date, end_date, is_purchase_log=False, file_name_for_error_msg=""):
    fh = download_excel_from_drive_as_bytes(_drive_service, file_id, file_name_for_error_msg)
    if fh is None: return pd.DataFrame()
    try:
        df = pd.read_excel(fh, sheet_name=sheet_name, header=0)
        df.dropna(how='all', inplace=True)
        if df.empty: return pd.DataFrame()
        if is_purchase_log:
            ffill_cols = [date_col, location_col, PURCHASE_CODE_COL, PURCHASE_CUSTOMER_COL]
            for col_to_ffill in ffill_cols:
                if col_to_ffill in df.columns: df[col_to_ffill] = df[col_to_ffill].ffill()
                elif col_to_ffill == date_col or col_to_ffill == location_col:
                    return pd.DataFrame()
        if date_col not in df.columns or qty_kg_col not in df.columns:
            return pd.DataFrame()
        df[date_col] = pd.to_datetime(df[date_col], errors='coerce').dt.normalize()
        df.dropna(subset=[date_col], inplace=True)
        df[qty_kg_col] = pd.to_numeric(df[qty_kg_col], errors='coerce').fillna(0)
        mask = (df[date_col].dt.date >= start_date) & (df[date_col].dt.date <= end_date)
        df_period = df.loc[mask].copy()
        if df_period.empty: return pd.DataFrame()
        df_period['ì›”'] = df_period[date_col].dt.strftime('%Y-%m')
        monthly_sum = df_period.groupby('ì›”')[qty_kg_col].sum().reset_index()
        monthly_sum.rename(columns={qty_kg_col: 'ì¤‘ëŸ‰(Kg)'}, inplace=True)
        return monthly_sum
    except Exception:
        return pd.DataFrame()

# --- í˜ì´ì§€ ë Œë”ë§ í•¨ìˆ˜ ---
def render_main_page_content():
    """ë©”ì¸ í˜ì´ì§€ì˜ ë°ì´í„° ë¶„ì„ ì½˜í…ì¸ ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    current_drive_service = st.session_state.drive_service
    
    now_time = datetime.datetime.now()
    current_time_str = now_time.strftime("%Y-%m-%d %H:%M:%S")
    st.markdown(f"<h1 style='text-align: center; margin-bottom: 0.1rem;'>ğŸ“Š ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ (ë©”ì¸)</h1>", unsafe_allow_html=True)
    st.markdown(f"<p style='text-align: center; margin-top: 0.1rem; font-size: 0.9em;'>í˜„ì¬ ì‹œê°„: {current_time_str}</p>", unsafe_allow_html=True)
    
    st.markdown("---")
    st.header("ğŸ“ˆ ì¬ê³  ë° ë¬¼ë¥˜ í˜„í™©")

    all_available_dates_desc = get_all_available_sheet_dates_from_excel_drive(current_drive_service, SM_FILE_ID, "SMì¬ê³ í˜„í™©.xlsx")
    dates_for_report = []
    if not all_available_dates_desc:
        st.warning("ê²½ê³ : 'SMì¬ê³ í˜„í™©.xlsx' íŒŒì¼ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë‚ ì§œ í˜•ì‹ì˜ ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        today = datetime.date.today()
        latest_anchor_date = next((dt for dt in all_available_dates_desc if dt <= today), None)
        if latest_anchor_date is None:
            st.warning(f"ê²½ê³ : ì˜¤ëŠ˜({today.strftime('%Y-%m-%d')}) ë˜ëŠ” ê·¸ ì´ì „ ë‚ ì§œì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê°€ì¥ ìµœê·¼ ë°ì´í„°ë¡œ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            latest_anchor_date = all_available_dates_desc[0]
        start_index = all_available_dates_desc.index(latest_anchor_date)
        end_index = min(start_index + 7, len(all_available_dates_desc))
        dates_for_report = all_available_dates_desc[start_index:end_index][:7]
        if dates_for_report:
            dates_for_report.sort()
            st.info(f"ë¶„ì„ ê¸°ê°„ ({len(dates_for_report)}ì¼ ë°ì´í„°): {dates_for_report[0].strftime('%Y-%m-%d')} ~ {dates_for_report[-1].strftime('%Y-%m-%d')}")
        else:
            st.warning("ê²½ê³ : ë¦¬í¬íŠ¸ì— ì‚¬ìš©í•  ë‚ ì§œë¥¼ ì„ ì •í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    report_dates_pd = pd.to_datetime(dates_for_report).normalize() if dates_for_report else pd.DatetimeIndex([])
    report_date_str_list_yyyymmdd = [d.strftime("%Y%m%d") for d in dates_for_report]
    df_sm_trend_raw = None
    if report_date_str_list_yyyymmdd:
        df_sm_trend_raw = load_sm_data_from_excel_drive(current_drive_service, SM_FILE_ID, report_date_str_list_yyyymmdd, "SMì¬ê³ í˜„í™©.xlsx")
    daily_location_summary = None
    if df_sm_trend_raw is not None and not df_sm_trend_raw.empty:
        df_sm_trend_filtered = df_sm_trend_raw[df_sm_trend_raw['ì§€ì ëª…'].isin(TARGET_SM_LOCATIONS_FOR_TREND)].copy()
        if not df_sm_trend_filtered.empty:
            df_sm_trend_filtered['ì°½ê³ ëª…'] = df_sm_trend_filtered['ì§€ì ëª…'].map(REPORT_LOCATION_MAP_TREND)
            daily_location_summary = df_sm_trend_filtered.groupby(['ë‚ ì§œ', 'ì°½ê³ ëª…'])[[SM_QTY_COL_TREND, SM_WGT_COL_TREND]].sum().reset_index()
    
    title_style = "<h3 style='margin-bottom:0.2rem; margin-top:0.5rem; font-size:1.25rem;'>"
    
    row1_cols = st.columns(3)
    with row1_cols[0]:
        st.markdown(f"{title_style}1. ì¼ë³„ ì¬ê³  ì¶”ì´</h3>", unsafe_allow_html=True)
        trend_unit_choice = st.radio("ì¶”ì´ ê¸°ì¤€ ì„ íƒ:", options=[SM_QTY_COL_TREND, SM_WGT_COL_TREND], horizontal=True, key='trend_unit')
        if daily_location_summary is not None and not daily_location_summary.empty and not report_dates_pd.empty:
            try:
                value_column = trend_unit_choice
                daily_location_summary['ë‚ ì§œ'] = pd.to_datetime(daily_location_summary['ë‚ ì§œ']).dt.normalize()
                chart_pivot_raw = daily_location_summary.pivot_table(index='ë‚ ì§œ', columns='ì°½ê³ ëª…', values=value_column)
                chart_pivot_final = chart_pivot_raw.reindex(index=report_dates_pd, columns=REPORT_ROW_ORDER_TREND).fillna(0)
                st.line_chart(chart_pivot_final, use_container_width=True, height=220)
            except Exception as e_chart1:
                st.error(f"ì¬ê³  ì¶”ì´ ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e_chart1}")
        elif dates_for_report:
            st.write("í‘œì‹œí•  ê·¸ë˜í”„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.write("ë°ì´í„° ë¡œë“œ ë¶ˆê°€ ë˜ëŠ” ë¶„ì„ ê¸°ê°„ ì—†ìŒ")

    with row1_cols[1]:
        st.markdown(f"{title_style}2. ì¬ê³  ë¹„ì¤‘ ({SM_QTY_COL_TREND})</h3>", unsafe_allow_html=True)
        if daily_location_summary is not None and not daily_location_summary.empty and not report_dates_pd.empty:
            latest_report_date_ts = report_dates_pd[-1]
            df_latest_day_stock = daily_location_summary[daily_location_summary['ë‚ ì§œ'] == latest_report_date_ts]
            if not df_latest_day_stock.empty and df_latest_day_stock[SM_QTY_COL_TREND].sum() > 0:
                fig_qty = px.pie(df_latest_day_stock, names='ì°½ê³ ëª…', values=SM_QTY_COL_TREND, hole=.4, title=f"{latest_report_date_ts.strftime('%m/%d')} (ë°•ìŠ¤)")
                fig_qty.update_traces(textposition='inside', textinfo='percent+label', pull=[0.05 if qty > 0 else 0 for qty in df_latest_day_stock[SM_QTY_COL_TREND]])
                fig_qty.update_layout(showlegend=False, title_x=0.5, margin=dict(t=40, b=20, l=20, r=20), height=280)
                st.plotly_chart(fig_qty, use_container_width=True)
            elif dates_for_report: st.write(f"{latest_report_date_ts.strftime('%m/%d')} ë°ì´í„° ì—†ìŒ")
            else: st.write("ë°ì´í„° ì—†ìŒ")
        elif dates_for_report: st.write("ìµœì‹ ì¼ì ë°ì´í„° ì—†ìŒ")
        else: st.write("ë°ì´í„° ë¡œë“œ ë¶ˆê°€ ë˜ëŠ” ë¶„ì„ ê¸°ê°„ ì—†ìŒ")

    with row1_cols[2]:
        st.markdown(f"{title_style}3. ì¬ê³  ë¹„ì¤‘ ({SM_WGT_COL_TREND})</h3>", unsafe_allow_html=True)
        if daily_location_summary is not None and not daily_location_summary.empty and not report_dates_pd.empty:
            latest_report_date_ts = report_dates_pd[-1]
            df_latest_day_stock_wgt = daily_location_summary[daily_location_summary['ë‚ ì§œ'] == latest_report_date_ts]
            if not df_latest_day_stock_wgt.empty and df_latest_day_stock_wgt[SM_WGT_COL_TREND].sum() > 0:
                fig_wgt = px.pie(df_latest_day_stock_wgt, names='ì°½ê³ ëª…', values=SM_WGT_COL_TREND, hole=.4, title=f"{latest_report_date_ts.strftime('%m/%d')} (Kg)")
                fig_wgt.update_traces(textposition='inside', textinfo='percent+label', pull=[0.05 if wgt > 0 else 0 for wgt in df_latest_day_stock_wgt[SM_WGT_COL_TREND]])
                fig_wgt.update_layout(showlegend=False, title_x=0.5, margin=dict(t=40, b=20, l=20, r=20), height=280)
                st.plotly_chart(fig_wgt, use_container_width=True)
            elif dates_for_report: st.write(f"{latest_report_date_ts.strftime('%m/%d')} ë°ì´í„° ì—†ìŒ")
            else: st.write("ë°ì´í„° ì—†ìŒ")
        elif dates_for_report: st.write("ìµœì‹ ì¼ì ë°ì´í„° ì—†ìŒ")
        else: st.write("ë°ì´í„° ë¡œë“œ ë¶ˆê°€ ë˜ëŠ” ë¶„ì„ ê¸°ê°„ ì—†ìŒ")
    
    st.markdown("---")

    st.markdown(f"{title_style}4. ì¼ë³„ ì°½ê³  ì¬ê³ ëŸ‰ ({SM_QTY_COL_TREND}/{SM_WGT_COL_TREND})</h3>", unsafe_allow_html=True); st.caption("í‘œê°€ ê¸¸ ê²½ìš° ìŠ¤í¬ë¡¤í•˜ì„¸ìš”.")
    if daily_location_summary is not None and not daily_location_summary.empty and not report_dates_pd.empty:
        try:
            table_pivot_qty = daily_location_summary.pivot_table(index='ì°½ê³ ëª…', columns='ë‚ ì§œ', values=SM_QTY_COL_TREND, fill_value=0).reindex(index=REPORT_ROW_ORDER_TREND, columns=report_dates_pd, fill_value=0)
            table_pivot_wgt = daily_location_summary.pivot_table(index='ì°½ê³ ëª…', columns='ë‚ ì§œ', values=SM_WGT_COL_TREND, fill_value=0).reindex(index=REPORT_ROW_ORDER_TREND, columns=report_dates_pd, fill_value=0)
            
            qty_diff = pd.DataFrame(index=table_pivot_qty.index, columns=table_pivot_qty.columns); daily_qty_totals = table_pivot_qty.sum(axis=0)
            daily_wgt_totals = table_pivot_wgt.sum(axis=0); total_qty_diff = pd.Series(dtype='float64', index=daily_qty_totals.index)
            
            if len(table_pivot_qty.columns) > 1: qty_diff = table_pivot_qty.diff(axis=1)
            if len(daily_qty_totals.index) > 1: total_qty_diff = daily_qty_totals.diff()

            combined_table = pd.DataFrame(index=table_pivot_qty.index, columns=pd.MultiIndex.from_tuples([(ts, KOREAN_DAYS[ts.weekday()]) for ts in table_pivot_qty.columns], names=['ë‚ ì§œ', 'ìš”ì¼_temp']), dtype=object)
            
            for date_col_ts in table_pivot_qty.columns:
                qty_series = table_pivot_qty[date_col_ts]; wgt_series = table_pivot_wgt[date_col_ts]; diff_series = qty_diff.get(date_col_ts)
                cell_strings = []
                for warehouse in table_pivot_qty.index:
                    qty_val = qty_series.get(warehouse, 0); wgt_val = wgt_series.get(warehouse, 0); diff_val = diff_series.get(warehouse, None) if diff_series is not None else None
                    base_string = f"{qty_val:,.0f} / {wgt_val:,.1f} Kg"; indicator = ""
                    if qty_val == 0 and wgt_val == 0: cell_strings.append("-")
                    else:
                        if pd.notnull(diff_val) and len(table_pivot_qty.columns) > 1:
                            if diff_val > 0.01: indicator = "ğŸ”º "
                            elif diff_val < -0.01: indicator = "â–¼ "
                        cell_strings.append(f"{indicator}{base_string}")
                combined_table[(date_col_ts, KOREAN_DAYS[date_col_ts.weekday()])] = cell_strings
            
            total_row_data = {}
            for date_col_ts in table_pivot_qty.columns:
                total_qty_val = daily_qty_totals.get(date_col_ts, 0); total_wgt_val = daily_wgt_totals.get(date_col_ts, 0); total_diff_val = total_qty_diff.get(date_col_ts, None)
                base_total_string = f"{total_qty_val:,.0f} / {total_wgt_val:,.1f} Kg"; total_indicator = ""
                if total_qty_val == 0 and total_wgt_val == 0:
                    total_row_data[(date_col_ts, KOREAN_DAYS[date_col_ts.weekday()])] = "-"
                else:
                    if pd.notnull(total_diff_val) and len(daily_qty_totals.index) > 1:
                        if total_diff_val > 0.01: total_indicator = "ğŸ”º "
                        elif total_diff_val < -0.01: total_indicator = "â–¼ "
                    total_row_data[(date_col_ts, KOREAN_DAYS[date_col_ts.weekday()])] = f"{total_indicator}{base_total_string}"
            
            combined_table.loc['í•©ê³„'] = pd.Series(total_row_data)
            combined_table.columns = [f"{ts.strftime('%m/%d')}({day})" for ts, day in combined_table.columns]
            
            combined_table_display = combined_table.reindex(REPORT_ROW_ORDER_TREND + ['í•©ê³„'])
            st.dataframe(combined_table_display.reset_index().rename(columns={'index': 'ì°½ê³ ëª…'}), hide_index=True, use_container_width=True, height=300)
        except Exception as e_table:
            st.error(f"í‘œ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜: {e_table}")
            traceback.print_exc()
    elif dates_for_report:
        st.write("í‘œì‹œí•  í…Œì´ë¸” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        if not report_dates_pd.empty:
            empty_table_cols = [ts.strftime('%m/%d') + f"({KOREAN_DAYS[ts.weekday()]})" for ts in report_dates_pd]
            empty_table_data = {col_name: ['-'] * (len(REPORT_ROW_ORDER_TREND) + 1) for col_name in empty_table_cols}
            empty_table_df = pd.DataFrame(empty_table_data, index=REPORT_ROW_ORDER_TREND + ['í•©ê³„']); empty_table_df.index.name = 'ì°½ê³ ëª…'
            st.dataframe(empty_table_df.reset_index(), hide_index=True, use_container_width=True, height=300)
    else:
        st.write("ë°ì´í„° ë¡œë“œ ë¶ˆê°€ ë˜ëŠ” ë¶„ì„ ê¸°ê°„ ì—†ìŒ")

    st.markdown("---")

    st.markdown(f"{title_style}5. ìµœê·¼ 7ì¼ ì¼ë³„ ì…ê³ /ì¶œê³  í˜„í™©</h3>", unsafe_allow_html=True)
    latest_purchase_date = get_latest_date_from_log_drive(current_drive_service, PURCHASE_FILE_ID, PURCHASE_LOG_SHEET_NAME, PURCHASE_DATE_COL, "ì…ê³ ë‚´ì—­.xlsx")
    latest_sales_date = get_latest_date_from_log_drive(current_drive_service, SALES_FILE_ID, SALES_LOG_SHEET_NAME, SALES_DATE_COL, "ì¶œê³ ë‚´ì—­.xlsx")
    overall_latest_date = None
    if latest_purchase_date and latest_sales_date: overall_latest_date = max(latest_purchase_date, latest_sales_date)
    elif latest_purchase_date: overall_latest_date = latest_purchase_date
    elif latest_sales_date: overall_latest_date = latest_sales_date
    
    if overall_latest_date:
        end_date_7day = overall_latest_date
        start_date_7day = end_date_7day - datetime.timedelta(days=6)
        period_caption = f"ê¸°ê°„: {start_date_7day.strftime('%Y-%m-%d')} ~ {end_date_7day.strftime('%Y-%m-%d')}"
        actual_7day_date_range = [start_date_7day + datetime.timedelta(days=i) for i in range(7)]
        log_cols = st.columns(2)
        with log_cols[0]:
            st.markdown("<h4 style='font-size:1.0rem; margin-bottom:0.1rem;'>ì¼ë³„ ì…ê³  í˜„í™© (Box/Kg)</h4>", unsafe_allow_html=True)
            st.caption(period_caption)
            df_purchase_daily_raw = load_daily_log_data_for_period_from_excel_drive(
                current_drive_service, PURCHASE_FILE_ID, PURCHASE_LOG_SHEET_NAME,
                PURCHASE_DATE_COL, PURCHASE_LOCATION_COL, PURCHASE_QTY_BOX_COL, PURCHASE_QTY_KG_COL,
                start_date_7day, end_date_7day,
                is_purchase_log=True, file_name_for_error_msg="ì…ê³ ë‚´ì—­.xlsx"
            )
            if df_purchase_daily_raw is not None and not df_purchase_daily_raw.empty:
                purchase_pivot_box = df_purchase_daily_raw.pivot_table(index=PURCHASE_LOCATION_COL, columns='ë‚ ì§œ', values='TotalQtyBox', fill_value=0)
                purchase_pivot_kg = df_purchase_daily_raw.pivot_table(index=PURCHASE_LOCATION_COL, columns='ë‚ ì§œ', values='TotalQtyKg', fill_value=0)
                purchase_pivot_box = purchase_pivot_box.reindex(index=SUMMARY_TABLE_LOCATIONS, columns=actual_7day_date_range, fill_value=0)
                purchase_pivot_kg = purchase_pivot_kg.reindex(index=SUMMARY_TABLE_LOCATIONS, columns=actual_7day_date_range, fill_value=0)
                purchase_combined_table = pd.DataFrame(index=purchase_pivot_box.index, columns=pd.MultiIndex.from_tuples([(d, KOREAN_DAYS[d.weekday()]) for d in purchase_pivot_box.columns]), dtype=object)
                daily_purchase_totals_box = purchase_pivot_box.sum(axis=0)
                daily_purchase_totals_kg = purchase_pivot_kg.sum(axis=0)
                for date_col_obj in purchase_pivot_box.columns:
                    for loc_idx, loc in enumerate(purchase_combined_table.index):
                        box = purchase_pivot_box.iloc[loc_idx][date_col_obj]
                        kg = purchase_pivot_kg.iloc[loc_idx][date_col_obj]
                        purchase_combined_table.loc[loc, (date_col_obj, KOREAN_DAYS[date_col_obj.weekday()])] = f"{box:,.0f} / {kg:,.1f}" if not (box == 0 and kg == 0) else "-"
                total_row_data_p = {}
                for date_obj in purchase_pivot_box.columns:
                    total_val_str = f"{daily_purchase_totals_box.get(date_obj, 0):,.0f} / {daily_purchase_totals_kg.get(date_obj, 0):,.1f}"
                    total_row_data_p[(date_obj, KOREAN_DAYS[date_obj.weekday()])] = total_val_str if not (daily_purchase_totals_box.get(date_obj, 0) == 0 and daily_purchase_totals_kg.get(date_obj, 0) == 0) else "-"
                purchase_combined_table.loc['í•©ê³„'] = pd.Series(total_row_data_p)
                purchase_combined_table.columns = [f"{d.strftime('%m/%d')}({day})" for d, day in purchase_combined_table.columns]
                st.dataframe(purchase_combined_table.reset_index().rename(columns={'index': 'ì§€ì ëª…'}), hide_index=True, use_container_width=True, height=250)
            else:
                st.write("í•´ë‹¹ ê¸°ê°„ ì…ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        with log_cols[1]:
            st.markdown("<h4 style='font-size:1.0rem; margin-bottom:0.1rem;'>ì¼ë³„ ì¶œê³  í˜„í™© (Box/Kg)</h4>", unsafe_allow_html=True)
            st.caption(period_caption)
            df_sales_daily_raw = load_daily_log_data_for_period_from_excel_drive(
                current_drive_service, SALES_FILE_ID, SALES_LOG_SHEET_NAME,
                SALES_DATE_COL, SALES_LOCATION_COL, SALES_QTY_BOX_COL, SALES_QTY_KG_COL,
                start_date_7day, end_date_7day,
                file_name_for_error_msg="ì¶œê³ ë‚´ì—­.xlsx"
            )
            if df_sales_daily_raw is not None and not df_sales_daily_raw.empty:
                sales_pivot_box = df_sales_daily_raw.pivot_table(index=SALES_LOCATION_COL, columns='ë‚ ì§œ', values='TotalQtyBox', fill_value=0)
                sales_pivot_kg = df_sales_daily_raw.pivot_table(index=SALES_LOCATION_COL, columns='ë‚ ì§œ', values='TotalQtyKg', fill_value=0)
                sales_pivot_box = sales_pivot_box.reindex(index=SUMMARY_TABLE_LOCATIONS, columns=actual_7day_date_range, fill_value=0)
                sales_pivot_kg = sales_pivot_kg.reindex(index=SUMMARY_TABLE_LOCATIONS, columns=actual_7day_date_range, fill_value=0)
                sales_combined_table = pd.DataFrame(index=sales_pivot_box.index, columns=pd.MultiIndex.from_tuples([(d, KOREAN_DAYS[d.weekday()]) for d in sales_pivot_box.columns]), dtype=object)
                daily_sales_totals_box = sales_pivot_box.sum(axis=0)
                daily_sales_totals_kg = sales_pivot_kg.sum(axis=0)
                for date_col_obj in sales_pivot_box.columns:
                    for loc_idx, loc in enumerate(sales_combined_table.index):
                        box = sales_pivot_box.iloc[loc_idx][date_col_obj]
                        kg = sales_pivot_kg.iloc[loc_idx][date_col_obj]
                        sales_combined_table.loc[loc, (date_col_obj, KOREAN_DAYS[date_col_obj.weekday()])] = f"{box:,.0f} / {kg:,.1f}" if not (box == 0 and kg == 0) else "-"
                total_row_data_s = {}
                for date_obj in sales_pivot_box.columns:
                    total_val_str = f"{daily_sales_totals_box.get(date_obj, 0):,.0f} / {daily_sales_totals_kg.get(date_obj, 0):,.1f}"
                    total_row_data_s[(date_obj, KOREAN_DAYS[date_obj.weekday()])] = total_val_str if not (daily_sales_totals_box.get(date_obj, 0) == 0 and daily_sales_totals_kg.get(date_obj, 0) == 0) else "-"
                sales_combined_table.loc['í•©ê³„'] = pd.Series(total_row_data_s)
                sales_combined_table.columns = [f"{d.strftime('%m/%d')}({day})" for d, day in sales_combined_table.columns]
                st.dataframe(sales_combined_table.reset_index().rename(columns={'index': 'ì§€ì ëª…'}), hide_index=True, use_container_width=True, height=250)
            else:
                st.write("í•´ë‹¹ ê¸°ê°„ ì¶œê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.write("ì…ê³ /ì¶œê³  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ìµœì‹  ë‚ ì§œ ì •ë³´ ì—†ìŒ).")

    st.markdown("---")

    st.markdown(f"{title_style}6. ì „ë…„ ë™ê¸° ì¤‘ëŸ‰ ë¹„êµ (Kg)</h3>", unsafe_allow_html=True)
    today = datetime.date.today()
    current_year_start = today.replace(month=1, day=1); current_year_end = today
    previous_year_start = current_year_start - relativedelta(years=1); previous_year_end = current_year_end - relativedelta(years=1)
    st.caption(f"ê¸°ê°„: ì˜¬í•´({current_year_start.strftime('%y/%m/%d')}~{current_year_end.strftime('%y/%m/%d')}) vs ì‘ë…„({previous_year_start.strftime('%y/%m/%d')}~{previous_year_end.strftime('%y/%m/%d')})")

    df_sales_cy = load_log_data_for_period_from_excel_drive(current_drive_service, SALES_FILE_ID, SALES_LOG_SHEET_NAME, SALES_DATE_COL, SALES_QTY_KG_COL, SALES_LOCATION_COL, current_year_start, current_year_end, file_name_for_error_msg="ì¶œê³ ë‚´ì—­.xlsx")
    df_sales_py = load_log_data_for_period_from_excel_drive(current_drive_service, SALES_FILE_ID, SALES_LOG_SHEET_NAME, SALES_DATE_COL, SALES_QTY_KG_COL, SALES_LOCATION_COL, previous_year_start, previous_year_end, file_name_for_error_msg="ì¶œê³ ë‚´ì—­.xlsx")
    df_purchase_cy = load_log_data_for_period_from_excel_drive(current_drive_service, PURCHASE_FILE_ID, PURCHASE_LOG_SHEET_NAME, PURCHASE_DATE_COL, PURCHASE_QTY_KG_COL, PURCHASE_LOCATION_COL, current_year_start, current_year_end, is_purchase_log=True, file_name_for_error_msg="ì…ê³ ë‚´ì—­.xlsx")
    df_purchase_py = load_log_data_for_period_from_excel_drive(current_drive_service, PURCHASE_FILE_ID, PURCHASE_LOG_SHEET_NAME, PURCHASE_DATE_COL, PURCHASE_QTY_KG_COL, PURCHASE_LOCATION_COL, previous_year_start, previous_year_end, is_purchase_log=True, file_name_for_error_msg="ì…ê³ ë‚´ì—­.xlsx")
    
    def prepare_comparison_df(df_cy, df_py, name_prefix):
        df_list = []
        if df_cy is not None and not df_cy.empty:
            df_cy_copy = df_cy.copy(); df_cy_copy['êµ¬ë¶„'] = f'{name_prefix} (ì˜¬í•´)'; df_list.append(df_cy_copy)
        if df_py is not None and not df_py.empty:
            df_py_copy = df_py.copy()
            df_py_copy['ì›”'] = pd.to_datetime(df_py_copy['ì›”']).apply(lambda x: x.replace(year=today.year)).dt.strftime('%Y-%m')
            df_py_copy['êµ¬ë¶„'] = f'{name_prefix} (ì‘ë…„)'; df_list.append(df_py_copy)
        
        if not df_list: return pd.DataFrame(columns=['ì›”', 'ì¤‘ëŸ‰(Kg)', 'êµ¬ë¶„'])
        
        combined = pd.concat(df_list)
        return combined

    def plot_comparison_chart(df_combined, title):
        if df_combined.empty or 'ì¤‘ëŸ‰(Kg)' not in df_combined.columns or df_combined['ì¤‘ëŸ‰(Kg)'].sum() == 0 :
            st.write(f"{title}: í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return
        
        df_combined_sorted = df_combined.copy()
        df_combined_sorted['ì›”_dt'] = pd.to_datetime(df_combined_sorted['ì›”'])
        df_combined_sorted = df_combined_sorted.sort_values('ì›”_dt')
        
        fig = px.line(df_combined_sorted, x='ì›”', y='ì¤‘ëŸ‰(Kg)', color='êµ¬ë¶„', markers=True,
                            title=title, labels={'ì›”': 'ì›”', 'ì¤‘ëŸ‰(Kg)': 'ì´ ì¤‘ëŸ‰(Kg)'})
        fig.update_layout(height=280, margin=dict(t=30, b=30, l=0, r=0), legend_title_text='')
        st.plotly_chart(fig, use_container_width=True)

    comparison_cols = st.columns(2)
    with comparison_cols[0]:
        df_purchase_compare = prepare_comparison_df(df_purchase_cy, df_purchase_py, "ì…ê³ ")
        plot_comparison_chart(df_purchase_compare, "ì›”ë³„ ì…ê³  ì¤‘ëŸ‰ ë¹„êµ")
    
    with comparison_cols[1]:
        df_sales_compare = prepare_comparison_df(df_sales_cy, df_sales_py, "ì¶œê³ ")
        plot_comparison_chart(df_sales_compare, "ì›”ë³„ ì¶œê³  ì¤‘ëŸ‰ ë¹„êµ")

# --- ì•± ì‹¤í–‰ ë¡œì§ ---
def main():
    """ì•±ì˜ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    # 1. Drive ì„œë¹„ìŠ¤ ê°ì²´ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì´ˆê¸°í™”í•©ë‹ˆë‹¤ (ì•± ì‹¤í–‰ ì‹œ í•œ ë²ˆë§Œ).
    if 'drive_service' not in st.session_state:
        st.session_state.drive_service = get_drive_service()

    # 2. Drive ì„œë¹„ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œëœ ê²½ìš°ì—ë§Œ ë‚˜ë¨¸ì§€ UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
    if st.session_state.get('drive_service'):
        # ëª¨ë“  í˜ì´ì§€ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•  ë©”ëª¨ ë°ì´í„°ì™€ ì‚¬ì´ë“œë°” ë²„íŠ¼ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        ensure_memos_loaded(st.session_state.drive_service, MEMO_FILE_ID)
        initialize_memo_sidebar(MEMO_FILE_ID)

        # í˜„ì¬ í˜ì´ì§€ì˜ ë©”ì¸ ì½˜í…ì¸ ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
        render_main_page_content()
        
        # í¬ìŠ¤íŠ¸ì‡ ë©”ëª¨ ë³´ë“œë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
        render_sticky_notes(MEMO_FILE_ID)

    else:
        st.error("Google Drive ì¸ì¦ ì •ë³´ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì•± ì„¤ì •ì„ í™•ì¸í•˜ê±°ë‚˜ ì•±ì„ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
